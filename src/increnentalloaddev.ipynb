{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Change the current working directory to the script's directory\n",
    "#os.chdir(script_dir)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "#import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "oldecon = pd.read_csv(r\"C:\\Users\\jonas\\Downloads\\newdatabase\\econW.csv\")\n",
    "max_date = (max(oldecon['Date']))\n",
    "\n",
    "print(max_date)\n",
    "start = datetime.datetime.strptime(max_date, '%Y-%m-%d')\n",
    "\n",
    "#end = datetime(2022, 5, 27)\n",
    "end = datetime.datetime.now()\n",
    "spread = web.DataReader('T10Y2Y', 'fred', start, end)\n",
    "spread.reset_index(inplace=True)\n",
    "spread.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "spread['Date']=pd.to_datetime(spread['Date'])\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() < 0, 'Inverted12months'] = 1\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() > 0, 'Inverted12months'] = 0\n",
    "    \n",
    "SP = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "Stock = pd.DataFrame(SP[['Date', 'Close']]).copy()\n",
    "\n",
    "Stock.reset_index(inplace=True)\n",
    "\n",
    "Stock['Date'] = pd.to_datetime(Stock['Date'])\n",
    "Stock['SP Daily Return'] = pd.to_numeric(Stock['Close'], errors='coerce')\n",
    "Stock['SP Daily Return'] = Stock['Close'].pct_change()\n",
    "Stock.isnull().sum()\n",
    "\n",
    "Stock['Cumulative Returns'] = (1 + Stock['SP Daily Return']).cumprod() - 1\n",
    "Stock.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "release_dates = pd.read_excel('https://alfred.stlouisfed.org/release/downloaddates?rid=10&ff=xls',skiprows= range(1,36))['Release: Consumer Price Index'].copy()\n",
    "\n",
    "release_dates = pd.to_datetime(release_dates)\n",
    "\n",
    "release_dates = pd.DataFrame(release_dates)\n",
    "release_dates.rename(columns={'Release: Consumer Price Index':'Release Date'}, inplace=True)\n",
    "\n",
    "release_dates['Date'] = release_dates['Release Date'] - pd.DateOffset(months=1)\n",
    "release_dates['Date'] = release_dates['Date'].to_numpy().astype('datetime64[M]')\n",
    "release_dates['Date'] = pd.to_datetime(release_dates['Date'])\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "cpius = fred.get_series_all_releases('CPIAUCNS', realtime_start=start.date())\n",
    "\n",
    "cpius = cpius.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "cpius = cpius.sort_index()\n",
    "\n",
    "cpius.reset_index(inplace= True)\n",
    "cpius = cpius.drop_duplicates(subset='Date', keep='last')\n",
    "cpius['MoM'] = cpius['value'].pct_change()\n",
    "cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
    "cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "cpius['Date'] = pd.to_datetime(cpius['Date']) \n",
    "cpius.rename({'value':'CPIUS'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "tradebalance = fred.get_series_all_releases('BOPGSTB', realtime_start=start.date())\n",
    "\n",
    "tradebalance = tradebalance.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "tradebalance = tradebalance.sort_index()\n",
    "\n",
    "tradebalance.reset_index(inplace= True)\n",
    "tradebalance = tradebalance.drop_duplicates(subset='Date', keep='last')\n",
    "tradebalance.sort_values(by='Date', ascending=True, inplace=True)\n",
    "tradebalance['value'] = tradebalance['value'].astype(float)\n",
    "\n",
    "tradebalance['MoM'] = (tradebalance['value'] - tradebalance['value'].shift(1).fillna(0)) / tradebalance['value'].shift(1).abs().replace(0, np.nan)\n",
    "tradebalance['YoY'] = (tradebalance['value'] - tradebalance['value'].shift(12).fillna(0)) / tradebalance['value'].shift(12).abs().replace(0, np.nan)\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([float('inf'), float('-inf')], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "\n",
    "tradebalance['RollingMean12'] = tradebalance['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "tradebalance['Date'] = pd.to_datetime(tradebalance['Date']) \n",
    "tradebalance.rename({'value':'Trade Balance'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'MoM':'Trade Balance MoM'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'YoY':'Trade Balance YoY'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "figsize(20, 5)\n",
    "pd.options.display.max_colwidth = 60\n",
    "\n",
    "m2 = fred.get_series_all_releases('M2SL', realtime_start=start.date())\n",
    "m2['date'] = pd.to_datetime(m2['date'])\n",
    "m2['value'] = m2['value'].astype(float)\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(m2.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "m2 = m2.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "m2.tail(10)\n",
    "m2 = m2.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "m2.reset_index(inplace= True)\n",
    "m2 = m2.drop_duplicates('Date', keep='last')\n",
    "m2['Date'] = pd.to_datetime(m2['Date'])\n",
    "m2.rename(columns={'value':'m2'}, inplace=True)\n",
    "    \n",
    "unemp = fred.get_series_all_releases('UNRATE', realtime_start=start.date())\n",
    "unemp['date'] = pd.to_datetime(unemp['date'])\n",
    "unemp['value'] = unemp['value'].astype(float)\n",
    "\n",
    "unemp['unemp_growth'] = unemp['value'].pct_change()\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(unemp.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "unemp = unemp.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "unemp.tail(10)\n",
    "unemp = unemp.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "unemp.reset_index(inplace= True)\n",
    "unemp = unemp.drop_duplicates('Date', keep='last')\n",
    "unemp['Date'] = pd.to_datetime(unemp['Date'])\n",
    "unemp.rename(columns={'value':'unemp_rate'}, inplace=True)\n",
    "    \n",
    "    \n",
    "tenyearmin = yf.Ticker(\"^TNX\").history(period='max')\n",
    "\n",
    "#tenyearmin = web.DataReader('DGS10', 'fred', start=start, end=end)\n",
    "tenyearmin = pd.DataFrame(tenyearmin['Close']).copy()\n",
    "\n",
    "tenyearmin.reset_index(inplace=True)\n",
    "\n",
    "tenyearmin['Date'] = pd.to_datetime(tenyearmin['Date'])\n",
    "\n",
    "oneyearmin = yf.Ticker(\"^IRX\").history(period='max')\n",
    "#oneyearmin = web.DataReader('DGS1', 'fred', start=start, end=end)\n",
    "oneyearmin = pd.DataFrame(oneyearmin['Close']).copy()\n",
    "\n",
    "oneyearmin.reset_index(inplace=True)\n",
    "\n",
    "oneyearmin['Date'] = pd.to_datetime(oneyearmin['Date'])\n",
    "\n",
    "yieldmin = oneyearmin.merge(tenyearmin, on=\"Date\")\n",
    "yieldmin['spread'] = yieldmin['Close_y'] - yieldmin['Close_x']\n",
    "\n",
    "yieldmin.rename(columns={'Close_x':'OneYearYield', 'Close_y':'TenYield'}, inplace=True)\n",
    "yieldmin.fillna(0, inplace=True)\n",
    "yieldmin.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "my_url = \"https://www.multpl.com/shiller-pe/table/by-month\"\n",
    "session = HTMLSession()\n",
    "response = session.get(my_url)\n",
    "page_content = response.text\n",
    "soup = bs(page_content, 'html.parser')\n",
    "\n",
    "\n",
    "table = soup.select(\"table\")[0]\n",
    "\n",
    "#actual_values = [link['left'] for link in table]\n",
    "\n",
    "columns = soup.find('th', class_=\"left\")\n",
    "\n",
    "table_rows = table.find_all(\"tr\")\n",
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [str(tr.get_text()).strip() for tr in td]\n",
    "    l.append(row) \n",
    "#print(table_rows)\n",
    "l=list(itertools.chain(*l))\n",
    "Dates = l[0::2]\n",
    "Values = l[1::2]\n",
    "shillers = pd.DataFrame(columns = [Dates, Values]).T.reset_index()\n",
    "shillers.columns = ['Date', 'Value']\n",
    "shillers['Date'] = pd.to_datetime(shillers['Date'], format='mixed')\n",
    "shillers['Value'] = shillers['Value'].astype(float)\n",
    "\n",
    "shiller = shillers\n",
    "\n",
    "shiller['Date'] = pd.to_datetime(shiller['Date'])\n",
    "shiller.columns = ['Date', 'Shiller_P/E'] \n",
    "\n",
    "composite_confidence = fred.get_series_all_releases('CSCICP03USM665S', realtime_start=start.date()) \n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "composite_confidence.head(20)\n",
    "composite_confidence['adjusted_value'] = composite_confidence['value'].shift(2).astype(float)\n",
    "composite_confidence['composite_confidence_growth_yoy'] = composite_confidence['adjusted_value'].pct_change(periods=12)\n",
    "composite_confidence['MoMConfidence'] = composite_confidence['composite_confidence_growth_yoy'].pct_change()\n",
    "composite_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "composite_confidence = composite_confidence.drop(['realtime_start', 'value'], axis=1).set_index('Date').reset_index()\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "composite_confidence['RollingComp'] = composite_confidence.adjusted_value.rolling(12).mean()\n",
    "composite_confidence\n",
    "\n",
    "inflation_exp = fred.get_series_all_releases('MICH', realtime_start=start.date()) #Total Consumer Credit\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "inflation_exp.head(20)\n",
    "inflation_exp['adjusted_value'] = inflation_exp['value'].shift(2).astype(float)\n",
    "inflation_exp['inflation_exp_yoy'] = inflation_exp['adjusted_value'].pct_change(periods=12)\n",
    "inflation_exp['MoMInflationExp'] = inflation_exp['inflation_exp_yoy'].pct_change()\n",
    "inflation_exp\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "inflation_exp = inflation_exp.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "inflation_exp['RollingExpInfl'] = inflation_exp.inflation_exp_yoy.rolling(12).mean()\n",
    "inflation_exp\n",
    "\n",
    "consumer_confidence = fred.get_series_all_releases('UMCSENT', realtime_start=start.date()) #Total Consumer Credit\n",
    "consumer_confidence.dropna(inplace=True)\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "consumer_confidence.head(20)\n",
    "consumer_confidence['adjusted_value'] = consumer_confidence['value'].shift(2).astype(float)\n",
    "consumer_confidence['consumer_conf_yoy'] = consumer_confidence['adjusted_value'].pct_change(periods=12)\n",
    "consumer_confidence['MoMConsumerConf'] = consumer_confidence['consumer_conf_yoy'].pct_change()\n",
    "consumer_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "consumer_confidence = consumer_confidence.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "consumer_confidence['RollingConsConf'] = consumer_confidence.consumer_conf_yoy.rolling(12).mean()\n",
    "consumer_confidence\n",
    "\n",
    "import_end = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = import_end - start_time\n",
    "print(f\"Elapsed time imports: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "import pytz\n",
    "time_zone = 'America/New_York'\n",
    "dfs = [completedates, Stock, cpius, m2, yieldmin, unemp, spread, shiller, consumer_confidence, inflation_exp, composite_confidence, tradebalance]\n",
    "for df in dfs:\n",
    "    #df = df.reset_index()\n",
    "    for col in df.columns:\n",
    "        if col == \"Date\":\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "            # extract just the date component\n",
    "            df[col] = df[col].dt.date\n",
    "            #df[col] = df[col].Date\n",
    "            \n",
    "econ = completedates.merge(Stock, on='Date', how='left').merge(cpius, on='Date', how='left').merge(m2, on='Date', how='left').merge(yieldmin, on='Date', how='left').merge(unemp, on='Date', how='left').merge(spread, on='Date', how='left').merge(shiller, on='Date', how='left').merge(consumer_confidence, on='Date', how='left').merge(inflation_exp, on='Date', how='left').merge(composite_confidence, on='Date', how='left').merge(tradebalance, on='Date', how='left').ffill()\n",
    "#.apply(lambda x : x.iloc[0]).head(32)\n",
    "econ.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "econ['real_yield'] = econ['TenYield'] - (econ['YoY']*100)\n",
    "from scipy import signal\n",
    "\n",
    "econ = econ.dropna(axis=0).copy()\n",
    "\n",
    "econ = econ.drop_duplicates()\n",
    "econ.Date = pd.to_datetime(econ['Date'])\n",
    "\n",
    "econ.set_index('Date', inplace=True)\n",
    "econW = econ\n",
    "\n",
    "econW.rename(columns={'inflation_exp_yoy':'InflationExp', 'consumer_conf_yoy':'ConsumerConfidence'}, inplace=True)\n",
    "econW.sort_values('Date', ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "#econW.to_csv(r'C:\\Users\\jonas\\OneDrive\\Skrivebord\\App\\econW.csv')\n",
    "#econW.to_csv(r'C:\\Users\\jonas\\Dropbox\\econW.csv')\n",
    "\n",
    "#print(max(econW.index))\n",
    "\n",
    "oldecon.set_index('Date', inplace=True)\n",
    "#econW = pd.concat([oldecon, econW], axis=0)\n",
    "\n",
    "#econW.to_csv(r'econWnew.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eedf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as web\n",
    "from fredapi import Fred\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "\n",
    "def load_existing_data(path):\n",
    "    \"\"\"Load existing economic data.\"\"\"\n",
    "    df = pd.read_csv(path, parse_dates=['Date'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df\n",
    "\n",
    "def get_new_dates(existing_df):\n",
    "    \"\"\"Get the latest date and define the new start date.\"\"\"\n",
    "    max_date = existing_df['Date'].max()\n",
    "    start = max_date + pd.Timedelta(days=1)\n",
    "    end = datetime.datetime.now()\n",
    "    return start, end\n",
    "\n",
    "def fetch_spread(start, end):\n",
    "    \"\"\"Fetch yield curve spread data.\"\"\"\n",
    "    df = web.DataReader('T10Y2Y', 'fred', start, end).reset_index()\n",
    "    df.rename(columns={'DATE': 'Date'}, inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df\n",
    "\n",
    "def fetch_sp500():\n",
    "    \"\"\"Fetch S&P 500 historical data.\"\"\"\n",
    "    sp = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "    sp = sp[['Date', 'Close']]\n",
    "    sp['Date'] = pd.to_datetime(sp['Date'])\n",
    "    return sp\n",
    "\n",
    "def fetch_fred_series(series_id, start):\n",
    "    \"\"\"Fetch a FRED series as a DataFrame.\"\"\"\n",
    "    df = fred.get_series_all_releases(series_id, realtime_start=start.date())\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "# --- LOAD EXISTING DATA ---\n",
    "\n",
    "oldecon_path = r\"C:\\Users\\jonas\\Downloads\\newdatabase\\econW.csv\"\n",
    "oldecon = load_existing_data(oldecon_path)\n",
    "start, end = get_new_dates(oldecon)\n",
    "\n",
    "# --- FETCH NEW DATA (UNTOUCHED) ---\n",
    "\n",
    "spread = fetch_spread(start, end)\n",
    "sp500 = fetch_sp500()\n",
    "cpius = fetch_fred_series('CPIAUCNS', start)\n",
    "m2 = fetch_fred_series('M2SL', start)\n",
    "unemp = fetch_fred_series('UNRATE', start)\n",
    "tradebalance = fetch_fred_series('BOPGSTB', start)\n",
    "# Add more series as needed...\n",
    "\n",
    "# --- MERGE ALL DATA ---\n",
    "\n",
    "# Create a date range for merging\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=end, freq='B'), columns=['Date'])\n",
    "\n",
    "# Merge all untouched data\n",
    "dfs = [completedates, sp500, cpius, m2, unemp, spread, tradebalance]\n",
    "for df in dfs:\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "econ_new = completedates\n",
    "for df in dfs[1:]:\n",
    "    econ_new = econ_new.merge(df, on='Date', how='left')\n",
    "\n",
    "# --- PERFORM CALCULATIONS AFTER MERGE ---\n",
    "\n",
    "econ_new['SP Daily Return'] = econ_new['Close'].pct_change()\n",
    "econ_new['Cumulative Returns'] = (1 + econ_new['SP Daily Return']).cumprod() - 1\n",
    "# Repeat similar calculations for other columns as needed\n",
    "\n",
    "# --- APPEND TO EXISTING DATA AND SAVE ---\n",
    "\n",
    "econ_combined = pd.concat([oldecon, econ_new], ignore_index=True)\n",
    "econ_combined = econ_combined.drop_duplicates(subset='Date').sort_values('Date')\n",
    "\n",
    "# Save to CSV if desired\n",
    "# econ_combined.to_csv(r'path_to_save.csv', index=False)\n",
    "\n",
    "print(\"Incremental update complete. Data shape:\", econ_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFIED DATA FETCH FUNCTIONS (RAW DATA ONLY) ---\n",
    "def fetch_spread(start, end):\n",
    "    \"\"\"Returns only raw spread data without calculations\"\"\"\n",
    "    spread = web.DataReader('T10Y2Y', 'fred', start, end).reset_index()\n",
    "    spread.rename(columns={'DATE': 'Date'}, inplace=True)\n",
    "    spread['Date'] = pd.to_datetime(spread['Date'])\n",
    "    return spread[['Date', 'T10Y2Y']]\n",
    "\n",
    "def fetch_confidence_indicators(start):\n",
    "    \"\"\"Returns raw confidence data without transformations\"\"\"\n",
    "    def get_raw_series(series_id, name):\n",
    "        df = fred.get_series_all_releases(series_id, realtime_start=start.date())\n",
    "        df = df.rename(columns={'value': name, 'date': 'Date'})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        return df[['Date', name]].drop_duplicates('Date')\n",
    "    \n",
    "    return {\n",
    "        'composite': get_raw_series('CSCICP03USM665S', 'CompositeConfidence'),\n",
    "        'inflation_exp': get_raw_series('MICH', 'InflationExpectations'),\n",
    "        'consumer': get_raw_series('UMCSENT', 'ConsumerConfidence')\n",
    "    }\n",
    "\n",
    "# --- UPDATED CALCULATION PHASE ---\n",
    "def calculate_metrics(combined_df):\n",
    "    \"\"\"Perform all calculations on merged historical + new data\"\"\"\n",
    "    # Yield curve calculations\n",
    "    combined_df['Inverted12months'] = (combined_df['T10Y2Y']\n",
    "                                        .rolling(window=153, min_periods=1)\n",
    "                                        .min() < 0).astype(int)\n",
    "    \n",
    "    # Stock market calculations\n",
    "    combined_df['SP Daily Return'] = combined_df['Close'].pct_change()\n",
    "    combined_df['Cumulative Returns'] = (1 + combined_df['SP Daily Return']).cumprod() - 1\n",
    "    \n",
    "    # Confidence indicators calculations\n",
    "    for prefix in ['Composite', 'InflationExpectations', 'Consumer']:\n",
    "        col = f\"{prefix}Confidence\"\n",
    "        if col in combined_df.columns:\n",
    "            combined_df[f'{col}_YoY'] = combined_df[col].pct_change(periods=12)\n",
    "            combined_df[f'{col}_MoM'] = combined_df[col].pct_change()\n",
    "            combined_df[f'{col}_Rolling'] = combined_df[col].rolling(12).mean()\n",
    "    \n",
    "    # Economic calculations\n",
    "    combined_df['real_yield'] = combined_df['TenYield'] - (combined_df['CPIUS'].pct_change(periods=12) * 100)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# --- MODIFIED WORKFLOW ---\n",
    "# 1. Load existing data\n",
    "oldecon = load_existing_data(oldecon_path)\n",
    "\n",
    "# 2. Get new raw data\n",
    "start, end = get_new_dates(oldecon)\n",
    "new_data = fetch_new_data(start, end)  # Includes all fetch functions\n",
    "\n",
    "# 3. Merge with historical data\n",
    "combined = pd.concat([oldecon, new_data], ignore_index=True)\n",
    "combined = combined.drop_duplicates(subset='Date').sort_values('Date')\n",
    "\n",
    "# 4. Perform calculations on complete dataset\n",
    "final_df = calculate_metrics(combined)\n",
    "\n",
    "# 5. Save updated data\n",
    "final_df.to_csv(updated_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d36899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data to fetch. Existing data is up-to-date.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from pandas_datareader import data as web\n",
    "from fredapi import Fred\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "oldecon_path = r\"C:\\Users\\jonas\\Downloads\\newdatabase\\econW_updated.csv\"\n",
    "updated_path = r\"C:\\Users\\jonas\\Downloads\\newdatabase\\econW_updated.csv\"\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "def load_existing_data(path):\n",
    "    \"\"\"Load existing dataset with date parsing\"\"\"\n",
    "    df = pd.read_csv(path).reset_index(drop=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df.sort_values('Date')\n",
    "\n",
    "def get_new_dates(existing_df):\n",
    "    \"\"\"Determine date range for incremental update\"\"\"\n",
    "    max_date = existing_df['Date'].max()\n",
    "    start = max_date + pd.Timedelta(days=1)\n",
    "    end = datetime.datetime.now()\n",
    "    return start, end\n",
    "\n",
    "def ensure_naive_dates(dfs):\n",
    "    \"\"\"Convert all Date columns to timezone-naive datetime\"\"\"\n",
    "    for df in dfs:\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize(None)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# --- DATA FETCHING FUNCTIONS (RAW DATA ONLY) ---\n",
    "def fetch_spread(start, end):\n",
    "    \"\"\"10Y-2Y Treasury Spread\"\"\"\n",
    "    df = web.DataReader('T10Y2Y', 'fred', start, end).reset_index()\n",
    "    return df.rename(columns={'DATE': 'Date'})[['Date', 'T10Y2Y']]\n",
    "\n",
    "def fetch_yahoo(ticker, name):\n",
    "    series = yf.Ticker(ticker).history(period='max').reset_index()\n",
    "    return series[['Date', 'Close']].rename(columns={'Close': name})\n",
    "\n",
    "def fetch_fred_series(series_id, start, name):\n",
    "    \"\"\"Generic FRED Series Fetcher\"\"\"\n",
    "    df = fred.get_series_all_releases(series_id, realtime_start=start.date())\n",
    "    return (df.rename(columns={'date': 'Date', 'value': name})\n",
    "            .drop('realtime_start', axis=1)\n",
    "            .drop_duplicates('Date'))\n",
    "\n",
    "\n",
    "def fetch_shiller_pe():\n",
    "    \"\"\"Shiller P/E Ratio from multpl.com\"\"\"\n",
    "    session = HTMLSession()\n",
    "    response = session.get(\"https://www.multpl.com/shiller-pe/table/by-month\")\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    \n",
    "    data = []\n",
    "    for tr in soup.select(\"table\")[0].find_all(\"tr\"):\n",
    "        td = tr.find_all('td')\n",
    "        if len(td) == 2:\n",
    "            data.append([\n",
    "                pd.to_datetime(td[0].get_text().strip(), errors='coerce'),\n",
    "                float(td[1].get_text().strip().replace(',', ''))\n",
    "            ])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['Date', 'Shiller_PE']).dropna()\n",
    "\n",
    "\n",
    "# --- MAIN WORKFLOW ---\n",
    "def main():\n",
    "    # 1. Load existing data\n",
    "    oldecon = load_existing_data(oldecon_path)\n",
    "    \n",
    "    # 2. Determine date range for update\n",
    "    start, end = get_new_dates(oldecon)\n",
    "    if start >= end:\n",
    "        print(\"No new data to fetch. Existing data is up-to-date.\")\n",
    "        combined = oldecon\n",
    "        combined.columns = oldecon.columns.str.lower().str.replace(' ', '_')\n",
    "        return combined\n",
    "    print(f\"Fetching new data from {start.date()} to {end.date()}\")\n",
    "    \n",
    "    # 3. Fetch all new raw data\n",
    "    new_data = {\n",
    "        'spread': fetch_spread(start, end),\n",
    "        'Close': fetch_yahoo('^GSPC', \"Close\"),\n",
    "        'TenYield': fetch_yahoo('^TNX', \"TenYield\"),\n",
    "        'CPIUS': fetch_fred_series('CPIAUCNS', start, 'CPIUS'),\n",
    "        'm2': fetch_fred_series('M2SL', start, 'm2'),\n",
    "        'unemp_rate': fetch_fred_series('UNRATE', start, 'unemp_rate'),\n",
    "        'Trade Balance': fetch_fred_series('BOPGSTB', start, 'Trade Balance'),\n",
    "        'Shiller_PE': fetch_shiller_pe()\n",
    "    }\n",
    "\n",
    "    # 4. Create complete date index\n",
    "    date_range = pd.date_range(start=start, end=end, freq='D')\n",
    "    combined = pd.DataFrame({'Date': date_range})\n",
    "\n",
    "    # 5. Merge all datasets\n",
    "    combined = pd.DataFrame({'Date': date_range})\n",
    "\n",
    "    # Convert all Date columns to naive datetime first\n",
    "    new_data = ensure_naive_dates(list(new_data.values()))  # Convert new data\n",
    "    oldecon = ensure_naive_dates([oldecon])[0]  # Convert existing data\n",
    "\n",
    "    for df in new_data:\n",
    "        if not df.empty:\n",
    "            combined = combined.merge(df, on='Date', how='left')\n",
    "\n",
    "\n",
    "    # 6. Combine with historical data\n",
    "    combined = pd.concat([oldecon, combined], ignore_index=True)\n",
    "    combined = combined.drop_duplicates('Date').sort_values('Date')\n",
    "\n",
    "    # 7. Perform all calculations\n",
    "    combined.ffill(inplace=True)  # Forward fill to handle NaNs\n",
    "    combined = calculate_metrics(combined)\n",
    "    combined.to_csv(updated_path, index=False)\n",
    "    combined.columns = combined.columns.str.lower().str.replace(' ', '_')\n",
    "    # 8. Save updated data\n",
    "    \n",
    "    print(f\"Update complete. New shape: {combined.shape}\")\n",
    "    combineddone = combined.copy()\n",
    "    return combineddone\n",
    "\n",
    "# --- CALCULATION ENGINE ---\n",
    "def calculate_metrics(df):\n",
    "    \"\"\"Post-merge calculations with full historical context\"\"\"\n",
    "    # Yield curve calculations\n",
    "    df['Inverted12months'] = (df['T10Y2Y']\n",
    "                             .rolling(153, min_periods=1)\n",
    "                             .min() < 0).astype(int)\n",
    "    \n",
    "    # Stock market calculations\n",
    "    df['SP Daily Return'] = df['Close'].pct_change()\n",
    "    df['Cumulative Returns'] = (1 + df['SP Daily Return']).cumprod() - 1\n",
    "    \n",
    "\n",
    "    df['Trade Balance MoM'] = (df['Trade Balance'] - df['Trade Balance'].shift(1).fillna(0)) / df['Trade Balance'].shift(1).abs().replace(0, np.nan)\n",
    "    df['Trade Balance YoY'] = (df['Trade Balance'] - df['Trade Balance'].shift(12).fillna(0)) / df['Trade Balance'].shift(12).abs().replace(0, np.nan)\n",
    "\n",
    "    # Replace problematic values (inf, -inf, NaN) with 0\n",
    "    df['Trade Balance MoM'] = df['Trade Balance MoM'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    df['Trade Balance YoY'] = df['Trade Balance YoY'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "    # Replace inf and -inf with 0\n",
    "    df['Trade Balance MoM'] = df['Trade Balance MoM'].replace([float('inf'), float('-inf')], 0)\n",
    "    df['Trade Balance YoY'] = df['Trade Balance YoY'].replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "\n",
    "    df['Trade Balance Rolling 12'] = df['Trade Balance'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "    # Economic calculations\n",
    "    df['Real_Yield'] = df['T10Y2Y'] - (df['CPIUS'].pct_change(12) * 100)\n",
    "    #df.ffill(inplace=True)  # Forward fill to handle NaNs\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combined = main()\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://postgres:9898@localhost:5432/postgres')\n",
    "print(f\"Max Date in Dataset before new load: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")\n",
    "\n",
    "engine = create_engine('postgresql://postgres:9898@localhost:5432/postgres')\n",
    "\n",
    "def load_incremental_data(new_data):\n",
    "    # Get max date from DB\n",
    "    max_date = pd.to_datetime(pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0])\n",
    "    \n",
    "    # Load new data from CSV\n",
    "    new_data = new_data[new_data['date'] > max_date]\n",
    "    \n",
    "    # Append to PostgreSQL\n",
    "    if not new_data.empty:\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            new_data.to_sql('econ', conn, schema='public', if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(new_data)} new rows into the database.\")\n",
    "    else:\n",
    "        print(\"No new data to load.\")\n",
    "\n",
    "# Schedule this function using cron/Airflow\n",
    "load_incremental_data(combined)\n",
    "print(f\"Latest date in the dataset after incremental load: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "47a28cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>sp_daily_return</th>\n",
       "      <th>sp_trailing_4_weeks_return</th>\n",
       "      <th>sp_trailing_1_week_return</th>\n",
       "      <th>cumulative_returns</th>\n",
       "      <th>cpius</th>\n",
       "      <th>cpi_mom</th>\n",
       "      <th>cpi_yoy</th>\n",
       "      <th>cpi_rolling_12</th>\n",
       "      <th>...</th>\n",
       "      <th>tenyield</th>\n",
       "      <th>unemp_rate</th>\n",
       "      <th>t10y2y</th>\n",
       "      <th>inverted12months</th>\n",
       "      <th>shiller_pe</th>\n",
       "      <th>trade_balance</th>\n",
       "      <th>trade_balance_mom</th>\n",
       "      <th>trade_balance_yoy</th>\n",
       "      <th>trade_balance_rolling_12</th>\n",
       "      <th>real_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-12-19</td>\n",
       "      <td>1305.599976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>-0.015489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-12-20</td>\n",
       "      <td>1264.739990</td>\n",
       "      <td>-0.031296</td>\n",
       "      <td>-0.045419</td>\n",
       "      <td>-0.046931</td>\n",
       "      <td>-0.031296</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-12-21</td>\n",
       "      <td>1274.859985</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>-0.058006</td>\n",
       "      <td>-0.083655</td>\n",
       "      <td>-0.023545</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.024387</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-12-25</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>5844.609863</td>\n",
       "      <td>-0.016135</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.476570</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.596</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0</td>\n",
       "      <td>34.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>5842.009766</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.474579</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.553</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>34.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>-0.006708</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>2025-05-24</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6416 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        close  sp_daily_return  sp_trailing_4_weeks_return  \\\n",
       "0    2000-12-19  1305.599976              NaN                   -0.036129   \n",
       "1    2000-12-20  1264.739990        -0.031296                   -0.045419   \n",
       "2    2000-12-21  1274.859985         0.008002                   -0.058006   \n",
       "3    2000-12-22  1305.949951         0.024387                   -0.053802   \n",
       "4    2000-12-25  1305.949951         0.000000                   -0.053802   \n",
       "...         ...          ...              ...                         ...   \n",
       "6411 2025-05-21  5844.609863        -0.016135                   -0.015303   \n",
       "6412 2025-05-22  5842.009766        -0.000445                   -0.015303   \n",
       "6413 2025-05-23  5802.819824        -0.006708                   -0.015303   \n",
       "6414 2025-05-24  5802.819824         0.000000                   -0.015303   \n",
       "6415 2025-05-25  5802.819824         0.000000                   -0.015303   \n",
       "\n",
       "      sp_trailing_1_week_return  cumulative_returns    cpius   cpi_mom  \\\n",
       "0                     -0.015489                 NaN  174.100  0.000575   \n",
       "1                     -0.046931           -0.031296  174.100  0.000575   \n",
       "2                     -0.083655           -0.023545  174.100  0.000575   \n",
       "3                     -0.070246            0.000268  174.100  0.000575   \n",
       "4                     -0.070246            0.000268  174.100  0.000575   \n",
       "...                         ...                 ...      ...       ...   \n",
       "6411                   0.005923            3.476570  320.795 -0.000542   \n",
       "6412                   0.005923            3.474579  320.795 -0.000542   \n",
       "6413                   0.005923            3.444562  320.795 -0.000542   \n",
       "6414                   0.005923            3.444562  320.795 -0.000542   \n",
       "6415                   0.005923            3.444562  320.795 -0.000542   \n",
       "\n",
       "       cpi_yoy  cpi_rolling_12  ...  tenyield  unemp_rate  t10y2y  \\\n",
       "0     0.034462        5.203506  ...     5.184         4.0   -0.16   \n",
       "1     0.034462        5.203506  ...     5.075         4.0   -0.16   \n",
       "2     0.034462        5.203506  ...     5.023         4.0   -0.11   \n",
       "3     0.034462        5.203506  ...     5.002         4.0   -0.08   \n",
       "4     0.034462        5.203506  ...     5.002         4.0   -0.08   \n",
       "...        ...             ...  ...       ...         ...     ...   \n",
       "6411  0.027494        0.029904  ...     4.596         4.2    0.58   \n",
       "6412  0.027494        0.029904  ...     4.553         4.2    0.54   \n",
       "6413  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "6414  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "6415  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "\n",
       "      inverted12months  shiller_pe  trade_balance  trade_balance_mom  \\\n",
       "0                    1       37.27       -29172.0                0.0   \n",
       "1                    1       37.27       -29172.0                0.0   \n",
       "2                    1       37.27       -29172.0                0.0   \n",
       "3                    1       37.27       -29172.0                0.0   \n",
       "4                    1       37.27       -29172.0                0.0   \n",
       "...                ...         ...            ...                ...   \n",
       "6411                 0       34.64      -140498.0                0.0   \n",
       "6412                 0       34.64      -140498.0                0.0   \n",
       "6413                 0       35.64      -140498.0                0.0   \n",
       "6414                 0       35.64      -140498.0                0.0   \n",
       "6415                 0       35.64      -140498.0                0.0   \n",
       "\n",
       "      trade_balance_yoy  trade_balance_rolling_12  real_yield  \n",
       "0                   0.0                       NaN         NaN  \n",
       "1                   0.0                       NaN         NaN  \n",
       "2                   0.0                       NaN         NaN  \n",
       "3                   0.0                       NaN         NaN  \n",
       "4                   0.0                       NaN         NaN  \n",
       "...                 ...                       ...         ...  \n",
       "6411                0.0                       0.0        0.58  \n",
       "6412                0.0                       0.0        0.54  \n",
       "6413                0.0                       0.0        0.51  \n",
       "6414                0.0                       0.0        0.51  \n",
       "6415                0.0                       0.0        0.51  \n",
       "\n",
       "[6416 rows x 21 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04859be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Date in Dataset before new load: 2025-05-25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://postgres:9898@localhost:5432/postgres')\n",
    "print(f\"Max Date in Dataset before new load: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")\n",
    "\n",
    "engine = create_engine('postgresql://postgres:9898@localhost:5432/postgres')\n",
    "\n",
    "def load_incremental_data(new_data):\n",
    "    # Get max date from DB\n",
    "    max_date = pd.to_datetime(pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0])\n",
    "    \n",
    "    # Load new data from CSV\n",
    "    new_data = new_data[new_data['date'] > max_date]\n",
    "    \n",
    "    # Append to PostgreSQL\n",
    "    if not new_data.empty:\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            new_data.to_sql('econ', conn, schema='public', if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(new_data)} new rows into the database.\")\n",
    "    else:\n",
    "        print(\"No new data to load.\")\n",
    "\n",
    "# Schedule this function using cron/Airflow\n",
    "load_incremental_data(combined)\n",
    "print(f\"Latest date in the dataset after incremental load: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data to load.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('postgresql://postgres:9898@localhost:5432/postgres')\n",
    "\n",
    "def load_incremental_data(new_data):\n",
    "    # Get max date from DB\n",
    "    max_date = pd.to_datetime(pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0])\n",
    "    \n",
    "    # Load new data from CSV\n",
    "    new_data = new_data[new_data['date'] > max_date]\n",
    "    \n",
    "    # Append to PostgreSQL\n",
    "    if not new_data.empty:\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            new_data.to_sql('econ', conn, schema='public', if_exists='append', index=False)\n",
    "        print(f\"Loaded {len(new_data)} new rows into the database.\")\n",
    "    else:\n",
    "        print(\"No new data to load.\")\n",
    "\n",
    "# Schedule this function using cron/Airflow\n",
    "load_incremental_data(combined)\n",
    "print(f\"Latest date in the dataset after incremental load: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "90028faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date in the dataset: 2025-05-25\n"
     ]
    }
   ],
   "source": [
    "print(f\"Latest date in the dataset: {pd.read_sql(\"SELECT MAX(date) FROM public.econ\", engine).iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3760cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>sp_daily_return</th>\n",
       "      <th>sp_trailing_4_weeks_return</th>\n",
       "      <th>sp_trailing_1_week_return</th>\n",
       "      <th>cumulative_returns</th>\n",
       "      <th>cpius</th>\n",
       "      <th>cpi_mom</th>\n",
       "      <th>cpi_yoy</th>\n",
       "      <th>cpi_rolling_12</th>\n",
       "      <th>...</th>\n",
       "      <th>tenyield</th>\n",
       "      <th>unemp_rate</th>\n",
       "      <th>t10y2y</th>\n",
       "      <th>inverted12months</th>\n",
       "      <th>shiller_pe</th>\n",
       "      <th>trade_balance</th>\n",
       "      <th>trade_balance_mom</th>\n",
       "      <th>trade_balance_yoy</th>\n",
       "      <th>trade_balance_rolling_12</th>\n",
       "      <th>real_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-12-19</td>\n",
       "      <td>1305.599976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>-0.015489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-12-20</td>\n",
       "      <td>1264.739990</td>\n",
       "      <td>-0.031296</td>\n",
       "      <td>-0.045419</td>\n",
       "      <td>-0.046931</td>\n",
       "      <td>-0.031296</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-12-21</td>\n",
       "      <td>1274.859985</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>-0.058006</td>\n",
       "      <td>-0.083655</td>\n",
       "      <td>-0.023545</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.024387</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-12-25</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>5.203506</td>\n",
       "      <td>...</td>\n",
       "      <td>5.002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>37.27</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>5844.609863</td>\n",
       "      <td>-0.016135</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.476570</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.596</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0</td>\n",
       "      <td>34.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>5842.009766</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.474579</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.553</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>34.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>-0.006708</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>2025-05-24</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>5802.819824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>3.444562</td>\n",
       "      <td>320.795</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>4.509</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>-140498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6416 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        close  sp_daily_return  sp_trailing_4_weeks_return  \\\n",
       "0    2000-12-19  1305.599976              NaN                   -0.036129   \n",
       "1    2000-12-20  1264.739990        -0.031296                   -0.045419   \n",
       "2    2000-12-21  1274.859985         0.008002                   -0.058006   \n",
       "3    2000-12-22  1305.949951         0.024387                   -0.053802   \n",
       "4    2000-12-25  1305.949951         0.000000                   -0.053802   \n",
       "...         ...          ...              ...                         ...   \n",
       "6411 2025-05-21  5844.609863        -0.016135                   -0.015303   \n",
       "6412 2025-05-22  5842.009766        -0.000445                   -0.015303   \n",
       "6413 2025-05-23  5802.819824        -0.006708                   -0.015303   \n",
       "6414 2025-05-24  5802.819824         0.000000                   -0.015303   \n",
       "6415 2025-05-25  5802.819824         0.000000                   -0.015303   \n",
       "\n",
       "      sp_trailing_1_week_return  cumulative_returns    cpius   cpi_mom  \\\n",
       "0                     -0.015489                 NaN  174.100  0.000575   \n",
       "1                     -0.046931           -0.031296  174.100  0.000575   \n",
       "2                     -0.083655           -0.023545  174.100  0.000575   \n",
       "3                     -0.070246            0.000268  174.100  0.000575   \n",
       "4                     -0.070246            0.000268  174.100  0.000575   \n",
       "...                         ...                 ...      ...       ...   \n",
       "6411                   0.005923            3.476570  320.795 -0.000542   \n",
       "6412                   0.005923            3.474579  320.795 -0.000542   \n",
       "6413                   0.005923            3.444562  320.795 -0.000542   \n",
       "6414                   0.005923            3.444562  320.795 -0.000542   \n",
       "6415                   0.005923            3.444562  320.795 -0.000542   \n",
       "\n",
       "       cpi_yoy  cpi_rolling_12  ...  tenyield  unemp_rate  t10y2y  \\\n",
       "0     0.034462        5.203506  ...     5.184         4.0   -0.16   \n",
       "1     0.034462        5.203506  ...     5.075         4.0   -0.16   \n",
       "2     0.034462        5.203506  ...     5.023         4.0   -0.11   \n",
       "3     0.034462        5.203506  ...     5.002         4.0   -0.08   \n",
       "4     0.034462        5.203506  ...     5.002         4.0   -0.08   \n",
       "...        ...             ...  ...       ...         ...     ...   \n",
       "6411  0.027494        0.029904  ...     4.596         4.2    0.58   \n",
       "6412  0.027494        0.029904  ...     4.553         4.2    0.54   \n",
       "6413  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "6414  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "6415  0.027494        0.029904  ...     4.509         4.2    0.51   \n",
       "\n",
       "      inverted12months  shiller_pe  trade_balance  trade_balance_mom  \\\n",
       "0                    1       37.27       -29172.0                0.0   \n",
       "1                    1       37.27       -29172.0                0.0   \n",
       "2                    1       37.27       -29172.0                0.0   \n",
       "3                    1       37.27       -29172.0                0.0   \n",
       "4                    1       37.27       -29172.0                0.0   \n",
       "...                ...         ...            ...                ...   \n",
       "6411                 0       34.64      -140498.0                0.0   \n",
       "6412                 0       34.64      -140498.0                0.0   \n",
       "6413                 0       35.64      -140498.0                0.0   \n",
       "6414                 0       35.64      -140498.0                0.0   \n",
       "6415                 0       35.64      -140498.0                0.0   \n",
       "\n",
       "      trade_balance_yoy  trade_balance_rolling_12  real_yield  \n",
       "0                   0.0                       NaN         NaN  \n",
       "1                   0.0                       NaN         NaN  \n",
       "2                   0.0                       NaN         NaN  \n",
       "3                   0.0                       NaN         NaN  \n",
       "4                   0.0                       NaN         NaN  \n",
       "...                 ...                       ...         ...  \n",
       "6411                0.0                       0.0        0.58  \n",
       "6412                0.0                       0.0        0.54  \n",
       "6413                0.0                       0.0        0.51  \n",
       "6414                0.0                       0.0        0.51  \n",
       "6415                0.0                       0.0        0.51  \n",
       "\n",
       "[6416 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb5dafa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully connected to the remote PostgreSQL server!\n",
      "PostgreSQL version: ('PostgreSQL 17.5 on x86_64-windows, compiled by msvc-19.43.34808, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Replace with your remote server details\n",
    "DB_HOST = \"127.0.0.1\"  # e.g., \"123.45.67.89\" or \"db.example.com\"\n",
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"9898\"\n",
    "DB_PORT = \"5432\"  # Default is 5432\n",
    "\n",
    "try:\n",
    "    # Create a connection\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        port=DB_PORT,\n",
    "       # sslmode=\"require\"  # Enable SSL for security\n",
    "    )\n",
    "    print(\"âœ… Successfully connected to the remote PostgreSQL server!\")\n",
    "\n",
    "    # Example: Run a test query\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT version();\")\n",
    "        print(\"PostgreSQL version:\", cur.fetchone())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()  # Always close the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import html, dcc\n",
    "#from update_script import update_dropbox_dataset\n",
    "from dash import dcc, callback, html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from updateEcon import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#dash.register_page(__name__, path='/economy')\n",
    "\n",
    "\n",
    "colors = {\n",
    "    'background': 'rgb(240,241,245)',\n",
    "    'text': 'black',\n",
    "    'accent': '#004172',\n",
    "    'text-white':'white',\n",
    "    'content':'#EDF3F4'\n",
    "}\n",
    "\n",
    "fonts = {\n",
    "    'heading': 'Helvetica',\n",
    "    'body': 'Helvetica'\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    'background': '#f4f4f4',\n",
    "    'banner': '#0a213b',\n",
    "    'banner2': '#1e3a5a',\n",
    "    'content': '#859db3',\n",
    "    'text': '#859db3',\n",
    "    'accent': '#004172',\n",
    "    'border': '#bed6eb',\n",
    "    'header': '#7a7a7a',\n",
    "    'element': '#1f8c44',\n",
    "    'text-white': 'white',\n",
    "}\n",
    "\n",
    "\n",
    "economy = pd.read_csv('econWupdated.csv', parse_dates=['Date'])\n",
    "economy['Date'] = pd.to_datetime(economy['Date'])\n",
    "\n",
    "latestdate = str(pd.to_datetime(economy['Date']).dt.date.tail(1).values[0])\n",
    "economy['unemp_rate'] = economy['unemp_rate'] / 100\n",
    "economy['TenYield'] = economy['TenYield'] / 100\n",
    "economy['Shiller_PE'] = round(economy['Shiller_PE'], 2)\n",
    "economy['Close'] = round(economy['Close'], 2)\n",
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Initialize FRED API\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "interest_payments = fred.get_series('A091RC1Q027SBEA', observation_start='2000-01-01')\n",
    "government_revenue = fred.get_series('FGRECPT', observation_start='2000-01-01')\n",
    "\n",
    "\n",
    "interest_df = pd.DataFrame(interest_payments, columns=['Interest Payments'])\n",
    "revenue_df = pd.DataFrame(government_revenue, columns=['Total Revenue'])\n",
    "\n",
    "df = pd.merge(interest_df, revenue_df, left_index=True, right_index=True)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index':'Date'}, inplace=True)\n",
    "\n",
    "# Calculate the interest-to-income ratio\n",
    "df['Interest to Income Ratio'] = ((df['Interest Payments'])/df['Total Revenue'])\n",
    "df['Interest to Income Ratio'] = round(df['Interest to Income Ratio'] , 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9987114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbdc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
