{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_44496\\3673035923.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['MoM'] = cpius['value'].pct_change()\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_44496\\3673035923.py:141: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_44496\\3673035923.py:142: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Change the current working directory to the script's directory\n",
    "#os.chdir(script_dir)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.models import load_model\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "#import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "#%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "\n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max')\n",
    "\n",
    "\n",
    "start = datetime.datetime(1980, 1, 1)\n",
    "#end = datetime(2022, 5, 27)\n",
    "end = datetime.datetime.now()\n",
    "spread = web.DataReader('T10Y2Y', 'fred', start, end)\n",
    "spread.reset_index(inplace=True)\n",
    "#plt.plot(spread.DATE, spread.T10Y2Y.add(0))\n",
    "spread.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "spread['Date']=pd.to_datetime(spread['Date'])\n",
    "\n",
    "#spread = spread.resample('D', on=\"Date\").min()\n",
    "#.apply(lambda x : x.iloc[0])\n",
    "\n",
    "#spread.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#spread.set_index('Date', inplace=True)\n",
    "#spread.reset_index(inplace=True)\n",
    "#spread = spread.drop('NotDate', axis=1)\n",
    "#spread.tail(50)\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() < 0, 'Inverted12months'] = 1\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() > 0, 'Inverted12months'] = 0\n",
    "    \n",
    "SP = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "Stock = pd.DataFrame(SP[['Date', 'Close']]).copy()\n",
    "\n",
    "Stock.reset_index(inplace=True)\n",
    "\n",
    "Stock['Date'] = pd.to_datetime(Stock['Date'])\n",
    "\n",
    "#Stock = Stock.resample('W-MON', on=\"Date\").apply(lambda x : x.iloc[0])\n",
    "#Stock\n",
    "#Stock.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#Stock.set_index('Date', inplace=True)\n",
    "#Stock.reset_index(inplace=True)\n",
    "#Stock = Stock.drop('NotDate', axis=1)\n",
    "\n",
    "Stock['SP Daily Return'] = Stock['Close'].pct_change()\n",
    "Stock['SP Trailing 4 Weeks Return'] = Stock['SP Daily Return'].shift(1).rolling(21, min_periods=21).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "Stock['SP Trailing 1 Week Return'] = Stock['SP Daily Return'].shift(1).rolling(7, min_periods=7).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "\n",
    "#Stock['SP Daily Return'].apply(lambda x: np.prod(1 + x) - 1)\n",
    "#.rolling\n",
    "#.prod()#.cumprod()\n",
    "#Stock\n",
    "Stock.isnull().sum()\n",
    "\n",
    "Stock['Cumulative Returns'] = (1 + Stock['SP Daily Return']).cumprod() - 1\n",
    "Stock.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "#df = pd.read_excel('sample.xlsx')\n",
    "\n",
    "#print(df)\n",
    "\n",
    "release_dates = pd.read_excel('https://alfred.stlouisfed.org/release/downloaddates?rid=10&ff=xls',skiprows= range(1,36))['Release: Consumer Price Index'].copy()\n",
    "\n",
    "release_dates = pd.to_datetime(release_dates)\n",
    "\n",
    "release_dates = pd.DataFrame(release_dates)\n",
    "release_dates.rename(columns={'Release: Consumer Price Index':'Release Date'}, inplace=True)\n",
    "\n",
    "#import datetime\n",
    "#import dateutil.relativedelta\n",
    "\n",
    "#years_ago = datetime.datetime.now() - relativedelta(years=7)\n",
    "release_dates['Date'] = release_dates['Release Date'] - pd.DateOffset(months=1)\n",
    "\n",
    "#\n",
    "\n",
    "#d = (\"2013-03-31\", \"%Y-%m-%d\")\n",
    "release_dates['Date'] = release_dates['Date'].to_numpy().astype('datetime64[M]')\n",
    "release_dates['Date'] = pd.to_datetime(release_dates['Date'])\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "cpius = fred.get_series_all_releases('CPIAUCNS', realtime_start=start.date())\n",
    "\n",
    "cpius = cpius.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "cpius = cpius.sort_index()\n",
    "\n",
    "cpius.reset_index(inplace= True)\n",
    "cpius = cpius.drop_duplicates(subset='Date', keep='last')\n",
    "# cpius = cpius.drop_duplicates('Date', keep='last')\n",
    "cpius['MoM'] = cpius['value'].pct_change()\n",
    "cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
    "cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "\n",
    "#cpius.reset_index(inplace= True)\n",
    "cpius['Date'] = pd.to_datetime(cpius['Date']) \n",
    "\n",
    "# cpius = cpius.merge(release_dates, on=\"Date\")\n",
    "\n",
    "# cpius = cpius.drop('Date', axis=1).rename(columns={'Release Date' : 'Date'}).set_index('Date')\n",
    "# cpius.reset_index(inplace= True)\n",
    "cpius.rename({'value':'CPIUS'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "tradebalance = fred.get_series_all_releases('BOPGSTB', realtime_start=start.date())\n",
    "\n",
    "tradebalance = tradebalance.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "tradebalance = tradebalance.sort_index()\n",
    "\n",
    "tradebalance.reset_index(inplace= True)\n",
    "tradebalance = tradebalance.drop_duplicates(subset='Date', keep='last')\n",
    "tradebalance.sort_values(by='Date', ascending=True, inplace=True)\n",
    "# tradebalance = tradebalance.drop_duplicates('Date', keep='last')\n",
    "\n",
    "# Convert 'value' to float to avoid integer division errors\n",
    "tradebalance['value'] = tradebalance['value'].astype(float)\n",
    "\n",
    "# Calculate MoM/YoY with safety checks\n",
    "tradebalance['MoM'] = (tradebalance['value'] - tradebalance['value'].shift(1).fillna(0)) / tradebalance['value'].shift(1).abs().replace(0, np.nan)\n",
    "tradebalance['YoY'] = (tradebalance['value'] - tradebalance['value'].shift(12).fillna(0)) / tradebalance['value'].shift(12).abs().replace(0, np.nan)\n",
    "\n",
    "# Replace problematic values (inf, -inf, NaN) with 0\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "# Replace inf and -inf with 0\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([float('inf'), float('-inf')], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "\n",
    "tradebalance['RollingMean12'] = tradebalance['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "\n",
    "#tradebalance.reset_index(inplace= True)\n",
    "tradebalance['Date'] = pd.to_datetime(tradebalance['Date']) \n",
    "\n",
    "# tradebalance = tradebalance.merge(release_dates, on=\"Date\")\n",
    "\n",
    "# tradebalance = tradebalance.drop('Date', axis=1).rename(columns={'Release Date' : 'Date'}).set_index('Date')\n",
    "# tradebalance.reset_index(inplace= True)\n",
    "tradebalance.rename({'value':'Trade Balance'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'MoM':'Trade Balance MoM'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'YoY':'Trade Balance YoY'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "#%matplotlib inline\n",
    "#from requests_html import AsyncHTMLSession\n",
    "figsize(20, 5)\n",
    "pd.options.display.max_colwidth = 60\n",
    "\n",
    "m2 = fred.get_series_all_releases('M2SL', realtime_start=start.date())\n",
    "m2['date'] = pd.to_datetime(m2['date'])\n",
    "m2['value'] = m2['value'].astype(float)\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(m2.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "m2 = m2.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "m2.tail(10)\n",
    "m2 = m2.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "m2.reset_index(inplace= True)\n",
    "m2 = m2.drop_duplicates('Date', keep='last')\n",
    "m2['Date'] = pd.to_datetime(m2['Date'])\n",
    "m2.rename(columns={'value':'m2'}, inplace=True)\n",
    "    \n",
    "#     # lei = fred.get_series_all_releases('USALOLITONOSTSAM')\n",
    "#     # lei['date'] = pd.to_datetime(lei['date'])\n",
    "#     # lei['value'] = lei['value'].astype(float)\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # meanvalues = pd.DataFrame(lei.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "    \n",
    "#     # lei = lei.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # lei.tail(10)\n",
    "#     # lei = lei.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "    \n",
    "#     # lei.reset_index(inplace= True)\n",
    "#     # lei =lei.drop_duplicates('Date', keep='last')\n",
    "#     # lei['Date'] = pd.to_datetime(lei['Date'])\n",
    "#     # lei.rename(columns={'value':'lei'}, inplace=True)\n",
    "    \n",
    "unemp = fred.get_series_all_releases('UNRATE', realtime_start=start.date())\n",
    "unemp['date'] = pd.to_datetime(unemp['date'])\n",
    "unemp['value'] = unemp['value'].astype(float)\n",
    "\n",
    "unemp['unemp_growth'] = unemp['value'].pct_change()\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(unemp.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "unemp = unemp.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "unemp.tail(10)\n",
    "unemp = unemp.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "unemp.reset_index(inplace= True)\n",
    "unemp = unemp.drop_duplicates('Date', keep='last')\n",
    "unemp['Date'] = pd.to_datetime(unemp['Date'])\n",
    "unemp.rename(columns={'value':'unemp_rate'}, inplace=True)\n",
    "    \n",
    "    \n",
    "tenyearmin = yf.Ticker(\"^TNX\").history(period='max')\n",
    "\n",
    "#tenyearmin = web.DataReader('DGS10', 'fred', start=start, end=end)\n",
    "tenyearmin = pd.DataFrame(tenyearmin['Close']).copy()\n",
    "\n",
    "tenyearmin.reset_index(inplace=True)\n",
    "\n",
    "tenyearmin['Date'] = pd.to_datetime(tenyearmin['Date'])\n",
    "\n",
    "oneyearmin = yf.Ticker(\"^IRX\").history(period='max')\n",
    "#oneyearmin = web.DataReader('DGS1', 'fred', start=start, end=end)\n",
    "oneyearmin = pd.DataFrame(oneyearmin['Close']).copy()\n",
    "\n",
    "oneyearmin.reset_index(inplace=True)\n",
    "\n",
    "oneyearmin['Date'] = pd.to_datetime(oneyearmin['Date'])\n",
    "\n",
    "yieldmin = oneyearmin.merge(tenyearmin, on=\"Date\")\n",
    "yieldmin['spread'] = yieldmin['Close_y'] - yieldmin['Close_x']\n",
    "\n",
    "yieldmin.rename(columns={'Close_x':'OneYearYield', 'Close_y':'TenYield'}, inplace=True)\n",
    "yieldmin.fillna(0, inplace=True)\n",
    "yieldmin.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "my_url = \"https://www.multpl.com/shiller-pe/table/by-month\"\n",
    "session = HTMLSession()\n",
    "response = session.get(my_url)\n",
    "page_content = response.text\n",
    "soup = bs(page_content, 'html.parser')\n",
    "\n",
    "\n",
    "#soup.find_all(\"h2\", string = re.compile(\"header\"))\n",
    "table = soup.select(\"table\")[0]\n",
    "\n",
    "#actual_values = [link['left'] for link in table]\n",
    "\n",
    "columns = soup.find('th', class_=\"left\")\n",
    "#columns\n",
    "\n",
    "table_rows = table.find_all(\"tr\")\n",
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [str(tr.get_text()).strip() for tr in td]\n",
    "    l.append(row) \n",
    "#print(table_rows)\n",
    "l=list(itertools.chain(*l))\n",
    "Dates = l[0::2]\n",
    "Values = l[1::2]\n",
    "\n",
    "\n",
    "# shillers['Date'] = pd.to_datetime(shillers['Date'])\n",
    "# shillers['Value'] = shillers['Value'].astype(float)\n",
    "\n",
    "# shiller = shillers\n",
    "\n",
    "\n",
    "# #shiller = pd.read_csv(r'C:\\Users\\jonas\\OneDrive\\Skrivebord\\shillers.csv')\n",
    "# shiller['Date'] = pd.to_datetime(shiller['Date'])\n",
    "# shiller.columns = ['Date', 'Shiller_P/E'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85040396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May 9, 2025</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 1, 2025</td>\n",
       "      <td>34.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 1, 2025</td>\n",
       "      <td>32.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar 1, 2025</td>\n",
       "      <td>34.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 1, 2025</td>\n",
       "      <td>37.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>Jun 1, 1871</td>\n",
       "      <td>12.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>May 1, 1871</td>\n",
       "      <td>12.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>Apr 1, 1871</td>\n",
       "      <td>12.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>Mar 1, 1871</td>\n",
       "      <td>11.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>Feb 1, 1871</td>\n",
       "      <td>10.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1853 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Value\n",
       "0     May 9, 2025  34.70\n",
       "1     May 1, 2025  34.64\n",
       "2     Apr 1, 2025  32.99\n",
       "3     Mar 1, 2025  34.98\n",
       "4     Feb 1, 2025  37.29\n",
       "...           ...    ...\n",
       "1848  Jun 1, 1871  12.59\n",
       "1849  May 1, 1871  12.59\n",
       "1850  Apr 1, 1871  12.05\n",
       "1851  Mar 1, 1871  11.19\n",
       "1852  Feb 1, 1871  10.92\n",
       "\n",
       "[1853 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shillers = pd.DataFrame(columns = [Dates, Values]).T.reset_index()\n",
    "shillers.columns = ['Date', 'Value']\n",
    "shillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb106a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2025-05-09\n",
       "1      2025-05-01\n",
       "2      2025-04-01\n",
       "3      2025-03-01\n",
       "4      2025-02-01\n",
       "          ...    \n",
       "1848   1871-06-01\n",
       "1849   1871-05-01\n",
       "1850   1871-04-01\n",
       "1851   1871-03-01\n",
       "1852   1871-02-01\n",
       "Name: Date, Length: 1853, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(shillers['Date'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d467750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time imports: 13.92 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Change the current working directory to the script's directory\n",
    "#os.chdir(script_dir)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.models import load_model\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "#import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "#%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "oldecon = pd.read_csv(r\"C:\\Users\\jonas\\Downloads\\newdatabase\\econW.csv\")\n",
    "max_date = (max(oldecon['Date']))\n",
    "\n",
    "\n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max')\n",
    "\n",
    "print(max_date)\n",
    "start = datetime.datetime.strptime(max_date, '%Y-%m-%d')\n",
    "\n",
    "#end = datetime(2022, 5, 27)\n",
    "end = datetime.datetime.now()\n",
    "spread = web.DataReader('T10Y2Y', 'fred', start, end)\n",
    "spread.reset_index(inplace=True)\n",
    "#plt.plot(spread.DATE, spread.T10Y2Y.add(0))\n",
    "spread.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "spread['Date']=pd.to_datetime(spread['Date'])\n",
    "\n",
    "#spread = spread.resample('D', on=\"Date\").min()\n",
    "#.apply(lambda x : x.iloc[0])\n",
    "\n",
    "#spread.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#spread.set_index('Date', inplace=True)\n",
    "#spread.reset_index(inplace=True)\n",
    "#spread = spread.drop('NotDate', axis=1)\n",
    "#spread.tail(50)\n",
    "#spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() < 0, 'Inverted12months'] = 1\n",
    "#spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() > 0, 'Inverted12months'] = 0\n",
    "    \n",
    "SP = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "Stock = pd.DataFrame(SP[['Date', 'Close']]).copy()\n",
    "\n",
    "Stock.reset_index(inplace=True)\n",
    "\n",
    "Stock['Date'] = pd.to_datetime(Stock['Date'])\n",
    "\n",
    "#Stock = Stock.resample('W-MON', on=\"Date\").apply(lambda x : x.iloc[0])\n",
    "#Stock\n",
    "#Stock.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#Stock.set_index('Date', inplace=True)\n",
    "#Stock.reset_index(inplace=True)\n",
    "#Stock = Stock.drop('NotDate', axis=1)\n",
    "Stock['SP Daily Return'] = pd.to_numeric(Stock['Close'], errors='coerce')\n",
    "Stock['SP Daily Return'] = Stock['Close'].pct_change()\n",
    "#Stock['SP Trailing 4 Weeks Return'] = Stock['SP Daily Return'].shift(1).rolling(21, min_periods=21).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "#Stock['SP Trailing 1 Week Return'] = Stock['SP Daily Return'].shift(1).rolling(7, min_periods=7).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "\n",
    "#Stock['SP Daily Return'].apply(lambda x: np.prod(1 + x) - 1)\n",
    "#.rolling\n",
    "#.prod()#.cumprod()\n",
    "#Stock\n",
    "Stock.isnull().sum()\n",
    "\n",
    "Stock['Cumulative Returns'] = (1 + Stock['SP Daily Return']).cumprod() - 1\n",
    "Stock.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "#df = pd.read_excel('sample.xlsx')\n",
    "\n",
    "#print(df)\n",
    "\n",
    "release_dates = pd.read_excel('https://alfred.stlouisfed.org/release/downloaddates?rid=10&ff=xls',skiprows= range(1,36))['Release: Consumer Price Index'].copy()\n",
    "\n",
    "release_dates = pd.to_datetime(release_dates)\n",
    "\n",
    "release_dates = pd.DataFrame(release_dates)\n",
    "release_dates.rename(columns={'Release: Consumer Price Index':'Release Date'}, inplace=True)\n",
    "\n",
    "#import datetime\n",
    "#import dateutil.relativedelta\n",
    "\n",
    "#years_ago = datetime.datetime.now() - relativedelta(years=7)\n",
    "release_dates['Date'] = release_dates['Release Date'] - pd.DateOffset(months=1)\n",
    "\n",
    "#\n",
    "\n",
    "#d = (\"2013-03-31\", \"%Y-%m-%d\")\n",
    "release_dates['Date'] = release_dates['Date'].to_numpy().astype('datetime64[M]')\n",
    "release_dates['Date'] = pd.to_datetime(release_dates['Date'])\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "cpius = fred.get_series_all_releases('CPIAUCNS', realtime_start=start.date())\n",
    "\n",
    "cpius = cpius.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "cpius = cpius.sort_index()\n",
    "\n",
    "cpius.reset_index(inplace= True)\n",
    "cpius = cpius.drop_duplicates(subset='Date', keep='last')\n",
    "# cpius = cpius.drop_duplicates('Date', keep='last')\n",
    "cpius['MoM'] = cpius['value'].pct_change()\n",
    "cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
    "cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "\n",
    "#cpius.reset_index(inplace= True)\n",
    "cpius['Date'] = pd.to_datetime(cpius['Date']) \n",
    "\n",
    "# cpius = cpius.merge(release_dates, on=\"Date\")\n",
    "\n",
    "# cpius = cpius.drop('Date', axis=1).rename(columns={'Release Date' : 'Date'}).set_index('Date')\n",
    "# cpius.reset_index(inplace= True)\n",
    "cpius.rename({'value':'CPIUS'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "tradebalance = fred.get_series_all_releases('BOPGSTB', realtime_start=start.date())\n",
    "\n",
    "tradebalance = tradebalance.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "tradebalance = tradebalance.sort_index()\n",
    "\n",
    "tradebalance.reset_index(inplace= True)\n",
    "tradebalance = tradebalance.drop_duplicates(subset='Date', keep='last')\n",
    "tradebalance.sort_values(by='Date', ascending=True, inplace=True)\n",
    "# tradebalance = tradebalance.drop_duplicates('Date', keep='last')\n",
    "\n",
    "# Convert 'value' to float to avoid integer division errors\n",
    "tradebalance['value'] = tradebalance['value'].astype(float)\n",
    "\n",
    "# Calculate MoM/YoY with safety checks\n",
    "tradebalance['MoM'] = (tradebalance['value'] - tradebalance['value'].shift(1).fillna(0)) / tradebalance['value'].shift(1).abs().replace(0, np.nan)\n",
    "tradebalance['YoY'] = (tradebalance['value'] - tradebalance['value'].shift(12).fillna(0)) / tradebalance['value'].shift(12).abs().replace(0, np.nan)\n",
    "\n",
    "# Replace problematic values (inf, -inf, NaN) with 0\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "# Replace inf and -inf with 0\n",
    "tradebalance['MoM'] = tradebalance['MoM'].replace([float('inf'), float('-inf')], 0)\n",
    "tradebalance['YoY'] = tradebalance['YoY'].replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "\n",
    "tradebalance['RollingMean12'] = tradebalance['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "\n",
    "#tradebalance.reset_index(inplace= True)\n",
    "tradebalance['Date'] = pd.to_datetime(tradebalance['Date']) \n",
    "\n",
    "# tradebalance = tradebalance.merge(release_dates, on=\"Date\")\n",
    "\n",
    "# tradebalance = tradebalance.drop('Date', axis=1).rename(columns={'Release Date' : 'Date'}).set_index('Date')\n",
    "# tradebalance.reset_index(inplace= True)\n",
    "tradebalance.rename({'value':'Trade Balance'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'MoM':'Trade Balance MoM'}, axis=1, inplace=True)\n",
    "tradebalance.rename({'YoY':'Trade Balance YoY'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "#%matplotlib inline\n",
    "#from requests_html import AsyncHTMLSession\n",
    "figsize(20, 5)\n",
    "pd.options.display.max_colwidth = 60\n",
    "\n",
    "m2 = fred.get_series_all_releases('M2SL', realtime_start=start.date())\n",
    "m2['date'] = pd.to_datetime(m2['date'])\n",
    "m2['value'] = m2['value'].astype(float)\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(m2.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "m2 = m2.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "m2.tail(10)\n",
    "m2 = m2.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "m2.reset_index(inplace= True)\n",
    "m2 = m2.drop_duplicates('Date', keep='last')\n",
    "m2['Date'] = pd.to_datetime(m2['Date'])\n",
    "m2.rename(columns={'value':'m2'}, inplace=True)\n",
    "    \n",
    "#     # lei = fred.get_series_all_releases('USALOLITONOSTSAM')\n",
    "#     # lei['date'] = pd.to_datetime(lei['date'])\n",
    "#     # lei['value'] = lei['value'].astype(float)\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # meanvalues = pd.DataFrame(lei.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "    \n",
    "#     # lei = lei.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # lei.tail(10)\n",
    "#     # lei = lei.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "    \n",
    "#     # lei.reset_index(inplace= True)\n",
    "#     # lei =lei.drop_duplicates('Date', keep='last')\n",
    "#     # lei['Date'] = pd.to_datetime(lei['Date'])\n",
    "#     # lei.rename(columns={'value':'lei'}, inplace=True)\n",
    "    \n",
    "unemp = fred.get_series_all_releases('UNRATE', realtime_start=start.date())\n",
    "unemp['date'] = pd.to_datetime(unemp['date'])\n",
    "unemp['value'] = unemp['value'].astype(float)\n",
    "\n",
    "unemp['unemp_growth'] = unemp['value'].pct_change()\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(unemp.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "unemp = unemp.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "unemp.tail(10)\n",
    "unemp = unemp.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "unemp.reset_index(inplace= True)\n",
    "unemp = unemp.drop_duplicates('Date', keep='last')\n",
    "unemp['Date'] = pd.to_datetime(unemp['Date'])\n",
    "unemp.rename(columns={'value':'unemp_rate'}, inplace=True)\n",
    "    \n",
    "    \n",
    "tenyearmin = yf.Ticker(\"^TNX\").history(period='max')\n",
    "\n",
    "#tenyearmin = web.DataReader('DGS10', 'fred', start=start, end=end)\n",
    "tenyearmin = pd.DataFrame(tenyearmin['Close']).copy()\n",
    "\n",
    "tenyearmin.reset_index(inplace=True)\n",
    "\n",
    "tenyearmin['Date'] = pd.to_datetime(tenyearmin['Date'])\n",
    "\n",
    "oneyearmin = yf.Ticker(\"^IRX\").history(period='max')\n",
    "#oneyearmin = web.DataReader('DGS1', 'fred', start=start, end=end)\n",
    "oneyearmin = pd.DataFrame(oneyearmin['Close']).copy()\n",
    "\n",
    "oneyearmin.reset_index(inplace=True)\n",
    "\n",
    "oneyearmin['Date'] = pd.to_datetime(oneyearmin['Date'])\n",
    "\n",
    "yieldmin = oneyearmin.merge(tenyearmin, on=\"Date\")\n",
    "yieldmin['spread'] = yieldmin['Close_y'] - yieldmin['Close_x']\n",
    "\n",
    "yieldmin.rename(columns={'Close_x':'OneYearYield', 'Close_y':'TenYield'}, inplace=True)\n",
    "yieldmin.fillna(0, inplace=True)\n",
    "yieldmin.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "my_url = \"https://www.multpl.com/shiller-pe/table/by-month\"\n",
    "session = HTMLSession()\n",
    "response = session.get(my_url)\n",
    "page_content = response.text\n",
    "soup = bs(page_content, 'html.parser')\n",
    "\n",
    "\n",
    "#soup.find_all(\"h2\", string = re.compile(\"header\"))\n",
    "table = soup.select(\"table\")[0]\n",
    "\n",
    "#actual_values = [link['left'] for link in table]\n",
    "\n",
    "columns = soup.find('th', class_=\"left\")\n",
    "#columns\n",
    "\n",
    "table_rows = table.find_all(\"tr\")\n",
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [str(tr.get_text()).strip() for tr in td]\n",
    "    l.append(row) \n",
    "#print(table_rows)\n",
    "l=list(itertools.chain(*l))\n",
    "Dates = l[0::2]\n",
    "Values = l[1::2]\n",
    "shillers = pd.DataFrame(columns = [Dates, Values]).T.reset_index()\n",
    "shillers.columns = ['Date', 'Value']\n",
    "shillers['Date'] = pd.to_datetime(shillers['Date'], format='mixed')\n",
    "shillers['Value'] = shillers['Value'].astype(float)\n",
    "\n",
    "shiller = shillers\n",
    "\n",
    "\n",
    "#shiller = pd.read_csv(r'C:\\Users\\jonas\\OneDrive\\Skrivebord\\shillers.csv')\n",
    "shiller['Date'] = pd.to_datetime(shiller['Date'])\n",
    "shiller.columns = ['Date', 'Shiller_P/E'] \n",
    "\n",
    "# consumer_credit = fred.get_series_all_releases('TOTLL') #Total Consumer Credit\n",
    "# consumer_credit['date'] = pd.to_datetime(consumer_credit['date'])\n",
    "# #lei.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "\n",
    "# consumer_credit['value'] = consumer_credit['value'].astype(float)\n",
    "# consumer_credit['consumer_credit_growth_yoy'] = consumer_credit['value'].pct_change(periods=12)\n",
    "# consumer_credit['MoMGrowthChange'] = consumer_credit['consumer_credit_growth_yoy'].pct_change()\n",
    "# consumer_credit\n",
    "# meanvalues = pd.DataFrame(consumer_credit.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "# consumer_credit = consumer_credit.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "# consumer_credit['consumer_credit_growth'] = consumer_credit['value'].pct_change(periods=12)\n",
    "# consumer_credit['MoMGrowthChange'] = consumer_credit['consumer_credit_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# consumer_credit.tail(10)\n",
    "# consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# consumer_credit.reset_index(inplace= True)\n",
    "# consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# consumer_credit['Date'] = pd.to_datetime(consumer_credit['Date'])\n",
    "# consumer_credit.rename(columns={'value':'consumer_credit_growth'}, inplace=True)\n",
    "# consumer_credit\n",
    "composite_confidence = fred.get_series_all_releases('CSCICP03USM665S', realtime_start=start.date()) \n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "composite_confidence.head(20)\n",
    "composite_confidence['adjusted_value'] = composite_confidence['value'].shift(2).astype(float)\n",
    "composite_confidence['composite_confidence_growth_yoy'] = composite_confidence['adjusted_value'].pct_change(periods=12)\n",
    "composite_confidence['MoMConfidence'] = composite_confidence['composite_confidence_growth_yoy'].pct_change()\n",
    "composite_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "composite_confidence = composite_confidence.drop(['realtime_start', 'value'], axis=1).set_index('Date').reset_index()\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "composite_confidence['RollingComp'] = composite_confidence.adjusted_value.rolling(12).mean()\n",
    "composite_confidence\n",
    "\n",
    "inflation_exp = fred.get_series_all_releases('MICH', realtime_start=start.date()) #Total Consumer Credit\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "inflation_exp.head(20)\n",
    "inflation_exp['adjusted_value'] = inflation_exp['value'].shift(2).astype(float)\n",
    "inflation_exp['inflation_exp_yoy'] = inflation_exp['adjusted_value'].pct_change(periods=12)\n",
    "inflation_exp['MoMInflationExp'] = inflation_exp['inflation_exp_yoy'].pct_change()\n",
    "inflation_exp\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "inflation_exp = inflation_exp.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "inflation_exp['RollingExpInfl'] = inflation_exp.inflation_exp_yoy.rolling(12).mean()\n",
    "inflation_exp\n",
    "\n",
    "consumer_confidence = fred.get_series_all_releases('UMCSENT', realtime_start=start.date()) #Total Consumer Credit\n",
    "consumer_confidence.dropna(inplace=True)\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "consumer_confidence.head(20)\n",
    "consumer_confidence['adjusted_value'] = consumer_confidence['value'].shift(2).astype(float)\n",
    "consumer_confidence['consumer_conf_yoy'] = consumer_confidence['adjusted_value'].pct_change(periods=12)\n",
    "consumer_confidence['MoMConsumerConf'] = consumer_confidence['consumer_conf_yoy'].pct_change()\n",
    "consumer_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "consumer_confidence = consumer_confidence.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "consumer_confidence['RollingConsConf'] = consumer_confidence.consumer_conf_yoy.rolling(12).mean()\n",
    "consumer_confidence\n",
    "\n",
    "import_end = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = import_end - start_time\n",
    "print(f\"Elapsed time imports: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# df = fred.search('ism')\n",
    "# #TOTALNS# ( Consumer Credit)\n",
    "# #TOTLL # Loans and leases\n",
    "# #CCLACBW027SBOGc\n",
    "# #PAYEMS (NON FARM PAYROLL)\n",
    "# # UMCSENT ( Consumer Confidence)\n",
    "# # MICH (Inflation Expectations)\n",
    "# # CSCICP03USM665S ( Composite Confidence Indicatiors) , two previous best\n",
    "\n",
    "# df.iloc[0,3]\n",
    "# df\n",
    "\n",
    "# housing = fred.get_series_all_releases('HSN1F') #Total Consumer Credit\n",
    "# housing.dropna(inplace=True)\n",
    "# housing['date'] = pd.to_datetime(housing['date'])\n",
    "\n",
    "# housing.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "# housing['adjusted_value'] = housing['value'].shift(2).astype(float)\n",
    "# housing['housing_yoy'] = housing['adjusted_value'].pct_change(periods=12)\n",
    "# housing['MoMRetail'] = housing['housing_yoy'].pct_change()\n",
    "# housing\n",
    "\n",
    "# #consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# #consumer_credit.reset_index(inplace= True)\n",
    "# #consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# housing['date'] = pd.to_datetime(housing['date'])\n",
    "# housing.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "# housing = housing.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "# housing['RollingHousing'] = housing.housing_yoy.rolling(12).mean()\n",
    "\n",
    "\n",
    "# claims = fred.get_series_all_releases('CFSBCACTIVITYNMFG') #Total Consumer Credit\n",
    "# claims.dropna(inplace=True)\n",
    "\n",
    "# claims = fred.get_series_all_releases('CFSBCACTIVITYNMFG') #Total Consumer Credit\n",
    "# claims.dropna(inplace=True)\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "\n",
    "# claims.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "# claims['adjusted_value'] = claims['value'].shift(2).astype(float)\n",
    "# claims['housing_yoy'] = claims['adjusted_value'].pct_change(periods=12)\n",
    "# claims['MoMRetail'] = claims['housing_yoy'].pct_change()\n",
    "# claims\n",
    "\n",
    "# #consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# #consumer_credit.reset_index(inplace= True)\n",
    "# #consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "# claims.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "# claims = claims.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "# claims['RollingHousing'] = claims.housing_yoy.rolling(12).mean()\n",
    "# claims\n",
    "# claims = fred.get_series_all_releases('ICSA')\n",
    "# claims.dropna(inplace=True)\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "# claims['value'] = claims['value'].astype(float)\n",
    "\n",
    "# claims['claims_growth'] = claims['value'].pct_change()\n",
    "# claims['claims_yoy'] = claims['value'].pct_change(periods=12)\n",
    "# #m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# meanvalues = pd.DataFrame(claims.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "# claims = claims.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "# #m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "# #m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# claims.tail(10)\n",
    "# claims = claims.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# claims.reset_index(inplace= True)\n",
    "# claims = claims.drop_duplicates('Date', keep='last')\n",
    "# claims['Date'] = pd.to_datetime(claims['Date'])\n",
    "# claims.rename(columns={'value':'claims'}, inplace=True)\n",
    "# claims\n",
    "\n",
    "import pytz\n",
    "\n",
    "time_zone = 'America/New_York'\n",
    "dfs = [completedates, Stock, cpius, m2, yieldmin, unemp, spread, shiller, consumer_confidence, inflation_exp, composite_confidence, tradebalance]\n",
    "for df in dfs:\n",
    "    #df = df.reset_index()\n",
    "    for col in df.columns:\n",
    "        if col == \"Date\":\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "            # extract just the date component\n",
    "            df[col] = df[col].dt.date\n",
    "            #df[col] = df[col].Date\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "econ = completedates.merge(Stock, on='Date', how='left').merge(cpius, on='Date', how='left').merge(m2, on='Date', how='left').merge(yieldmin, on='Date', how='left').merge(unemp, on='Date', how='left').merge(spread, on='Date', how='left').merge(shiller, on='Date', how='left').merge(consumer_confidence, on='Date', how='left').merge(inflation_exp, on='Date', how='left').merge(composite_confidence, on='Date', how='left').merge(tradebalance, on='Date', how='left').ffill()\n",
    "#.apply(lambda x : x.iloc[0]).head(32)\n",
    "econ.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "econ['real_yield'] = econ['TenYield'] - (econ['YoY']*100)\n",
    "#plt.plot(econ.Date, econ.real_yield)\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "econ = econ.dropna(axis=0).copy()\n",
    "# detrended = signal.detrend(econ.m2)\n",
    "\n",
    "# detrended_df = pd.DataFrame(detrended)\n",
    "\n",
    "\n",
    "# econ['detrendedm2'] = detrended\n",
    "# #econ['M2Detrend'] = econ.detrendedm2.diff(252)\n",
    "# #econ['CPIDeviation'] = abs(econ['CPIDetrend'] - econ['CPIDetrend'].mean())\n",
    "\n",
    "# #plt.plot(econ['Date'], econ['m2'].apply(np.log).diff(252).rolling(120).mean())\n",
    "# econ['mom2diff'] = econ['m2'].apply(np.log).diff(252).diff(252).rolling(1).mean()\n",
    "\n",
    "# #def calc_MDD(Stock):\n",
    "# df = pd.Series(econ['TenYield'], name=\"nw\").to_frame()\n",
    "\n",
    "# min_peaks_idx = df.nw.expanding(min_periods=1).apply(lambda x: x.argmin()).fillna(0).astype(int)\n",
    "# df['max_peaks_idx'] = pd.Series(min_peaks_idx).to_frame()\n",
    "\n",
    "# min_peaks = pd.Series(df.nw.iloc[min_peaks_idx.values].values, index=df.nw.index)\n",
    "\n",
    "# df['dd'] = ((df.nw-min_peaks)/min_peaks)\n",
    "# df['maxtightening'] = df.groupby('max_peaks_idx').dd.apply(lambda x: x.expanding(min_periods=1).apply(lambda y: y.max())).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# #  return df\n",
    "\n",
    "# econ['maxtight'] = df['maxtightening']\n",
    "\n",
    "# econ['TenYieldNorm'] = econ.TenYield.rolling(window=104).mean().copy()\n",
    "# econ['TenYieldNorm'] =(((econ['TenYieldNorm']  -\n",
    "# econ['TenYieldNorm'] .min()) /\n",
    "# (econ['TenYieldNorm'] .max() -\n",
    "# econ['TenYieldNorm'] .min())) * 100).copy()\n",
    "\n",
    "# from scipy import signal\n",
    "\n",
    "# econ = econ.ffill().dropna(axis=0).copy()\n",
    "# detrended = signal.detrend(econ.TenYieldNorm)\n",
    "\n",
    "# detrended_df = pd.DataFrame(detrended)\n",
    "# econ['detrendedyield'] = detrended\n",
    "# plt.plot(econ['Date'], econ.detrendedyield.add(200).apply(np.log))\n",
    "# plt.plot(econ['Date'], econ.detrendedyield)\n",
    "\n",
    "# econ['Shiller_P/E']\n",
    "\n",
    "# detrended = signal.detrend(econ['Shiller_P/E'])\n",
    "\n",
    "# detrended_df = pd.DataFrame(detrended)\n",
    "\n",
    "\n",
    "# econ['detrendedshiller'] = detrended\n",
    "\n",
    "\n",
    "            \n",
    "#         # .add(200).apply(np.log))\n",
    "        \n",
    "# econ.loc[econ['detrendedshiller'] >= 0, 'ShillerOver'] = econ['detrendedshiller']\n",
    "# econ.loc[econ['detrendedshiller'] < 0, 'ShillerOver'] = 0\n",
    "\n",
    "# plt.plot(econ['Date'], econ['detrendedshiller'])\n",
    "\n",
    "# econ['CPIDetrend'] = econ['YoY'].rolling(window=104).mean().diff()\n",
    "# econ['CPIDeviation'] = abs(econ['CPIDetrend'] - econ['CPIDetrend'].mean())\n",
    "# econ['CPIGoalDev'] = abs(econ['CPIDetrend'] - 0.02) \n",
    "\n",
    "# #plt.plot(econ['Date'],)\n",
    "\n",
    "# #plt.plot(econ['Date'], econ['CPIGoalDev'])\n",
    "\n",
    "# econ['CPIDev'] = econ['YoY'].rolling(window=104).max()\n",
    "\n",
    "# econ.loc[econ['CPIDev'] >= 0.02, 'CPIOver'] = econ['CPIDev']\n",
    "# econ.loc[econ['CPIDev'] < 0.02, 'CPIOver'] = 0.02\n",
    "\n",
    "# #scoreddf.loc[scoreddf['Combined Economy Score'] < 28, 'Long-Short'] = -1\n",
    "# #scoreddf.loc[scoreddf['Combined Economy Score'] >= 28, 'Long-Short'] = 1\n",
    "\n",
    "# #plt.plot(econ['Date'], econ['CPIOver'])\n",
    "# # =============================================================================\n",
    "# #         plt.plot(econ.Date, econ['spread'].rolling(window=104).mean().diff(50))\n",
    "# # \n",
    "# #         plt.plot(econ.Date, econ['YoY'].rolling(window=20).max())\n",
    "# # =============================================================================\n",
    "\n",
    "# scoreddf = econ[['Date', 'Shiller_P/E', 'detrendedshiller', 'ShillerOver', 'SP Daily Return', 'YoY', 'MoM', 'spread', 'm2', 'CPIOver', 'unemp_rate', 'unemp_growth', 'CPIDeviation', 'mom2diff', 'TenYield', 'real_yield', 'Inverted12months', 'Close', 'T10Y2Y', 'detrendedyield']].copy()\n",
    "# #scoreddf = scoreddf[scoreddf['Date'] > '2000-01-01'].copy()\n",
    "\n",
    "# #scoreddf['DeviationCPI'] = abs(scoreddf['YoYCPI']-0.02)\n",
    "\n",
    "# scoreddf['rollingtight'] = scoreddf['detrendedyield'].rank(method= \"average\",ascending=False)\n",
    "# #scoreddf['rollingtight'] = scoreddf['maxtight'].rolling(window=52).max().pct_change(periods=52).astype(float).rank(method= \"average\",ascending=False)\n",
    "# scoreddf['UnempScore'] = scoreddf['unemp_rate'].astype(float).rank(method= \"average\",ascending=False)# pct=True).copy()*100\n",
    "# scoreddf['Yield%Score'] = scoreddf['real_yield'].astype(float).astype(float).rank(method= \"average\",ascending=False)#, pct=True).copy()*100\n",
    "# scoreddf['SPReturn'] = scoreddf['SP Daily Return'].shift().astype(float).astype(float).rank(method= \"average\",ascending=True)#, pct=True).copy()*100\n",
    "# scoreddf['Rolling CPI'] = scoreddf['YoY'].astype(float).astype(float).rank(method= \"average\",ascending=False)#, pct=True).copy()*100\n",
    "# scoreddf['MoMCPI'] = scoreddf['MoM'].rolling(100).mean().astype(float).astype(float).rank(method= \"average\",ascending=False)#, pct=True).copy()*100\n",
    "# scoreddf['MoMM2'] = scoreddf['mom2diff'].astype(float).astype(float).rank(method= \"average\",ascending=True)#\", pct=True).copy()*100\n",
    "# #scoreddf['maxtightscore'] = scoreddf['maxtight'].astype(float).astype(float).rank(method= \"average\",ascending=False)#\", pct=True).copy()*100\n",
    "# #scoreddf['spreadscore'] = scoreddf['spread'].rolling(window=104).mean().diff().astype(float).rank(method= \"average\",ascending=True)#\", pct=True).copy()*100\n",
    "# scoreddf['CPIDevScore'] = scoreddf['YoY'].rolling(window=20).max().astype(float).rank(method= \"average\",ascending=False)#\", pct=True).copy()*100\n",
    "# scoreddf['CPIOverScore'] = scoreddf['CPIOver'].astype(float).rank(method= \"average\",ascending=False)#\", pct=True).copy()*100\n",
    "# scoreddf['realspread'] =  scoreddf['T10Y2Y'].rank(method= \"average\",ascending=True)#\", pct=True).copy()*100\n",
    "# #scoreddf['shillerscore'] =  scoreddf['Shiller_P/E'].apply(np.log).diff(10).rolling(126).mean().rank(method= \"average\",ascending=True)#\", pct=True).copy()*100\n",
    "# scoreddf['shillerscoreBear'] =  scoreddf['ShillerOver'].rank(method= \"average\",ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# scoreddf['Combined Economy Score'] = (scoreddf['UnempScore']*15  +\n",
    "#                                             scoreddf['Yield%Score']*222  +\n",
    "#                                             #scoreddf['SPReturn'] * 2+\n",
    "#                                             scoreddf['Rolling CPI']*400 +\n",
    "#                                             #scoreddf['MoMCPI'] * 100 +\n",
    "#                                             scoreddf['MoMM2']*100  +\n",
    "#                                             scoreddf['rollingtight']*295+\n",
    "#                                             #scoreddf['spreadscore']*100 +\n",
    "#                                             scoreddf['CPIDevScore']*600+\n",
    "#                                             scoreddf['CPIOverScore']*0+\n",
    "#                                             scoreddf['shillerscoreBear']*0)\n",
    "\n",
    "\n",
    "\n",
    "                                        \n",
    "# scoreddf['Combined Economy Score'] = (\n",
    "# (scoreddf['Combined Economy Score'] -\n",
    "# scoreddf['Combined Economy Score'].min()) /\n",
    "# (scoreddf['Combined Economy Score'].max() -\n",
    "# scoreddf['Combined Economy Score'].min())) * 100\n",
    "\n",
    "\n",
    "# finalscores = scoreddf[['Date', 'Combined Economy Score', 'Inverted12months', 'Close', 'SP Daily Return', 'rollingtight', 'UnempScore']].copy()\n",
    "\n",
    "# # 75 % percentile 283\n",
    "# # 25 % percentile 224\n",
    "\n",
    "# finalscores.head()\n",
    "# #scoreddf.tail(50)\n",
    "\n",
    "# #def calc_MDD(Stock):\n",
    "# df = pd.Series(finalscores['Close'], name=\"nw\").to_frame()\n",
    "\n",
    "# max_peaks_idx = df.nw.expanding(min_periods=1).apply(lambda x: x.argmax()).fillna(0).astype(int)\n",
    "# df['max_peaks_idx'] = pd.Series(max_peaks_idx).to_frame()\n",
    "\n",
    "# nw_peaks = pd.Series(df.nw.iloc[max_peaks_idx.values].values, index=df.nw.index)\n",
    "\n",
    "# df['dd'] = ((df.nw-nw_peaks)/nw_peaks)\n",
    "# df['mdd'] = df.groupby('max_peaks_idx').dd.apply(lambda x: x.expanding(min_periods=1).apply(lambda y: y.min())).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# #  return df\n",
    "\n",
    "# df\n",
    "\n",
    "# finalscores['maxdrawdown'] = df['mdd'].astype(float)\n",
    "\n",
    "# finalscores.loc[finalscores['maxdrawdown'] > -0.2 , 'BearMarket'] = 0\n",
    "# finalscores.loc[finalscores['maxdrawdown'] <= -0.2 , 'BearMarket'] = 1\n",
    "# #plt.plot(finalscores.Date, finalscores.maxdrawdown)#\n",
    "\n",
    "# finalscores['Rolling Bear'] = finalscores.loc[:,'BearMarket'].rolling(58).max().copy()\n",
    "\n",
    "# #finalscores['InvertandBear'] = finalscores['Rolling Bear']*finalscores['Inverted12months']\n",
    "\n",
    "# #finalscores['InvertandBear'] = finalscores['InvertandBear'].copy().fillna(0)\n",
    "# finalscores['InvertandBearFinal'] = finalscores['Inverted12months'] #- finalscores['InvertandBear']\n",
    "\n",
    "\n",
    "\n",
    "# finalscores = finalscores[['Date', 'Combined Economy Score', 'InvertandBearFinal', 'Inverted12months']].dropna().copy()\n",
    "\n",
    "\n",
    "\n",
    "# scoreddf['CumReturns'] = ((1+scoreddf.Close.pct_change()).cumprod()-1)*100\n",
    "\n",
    "# import numpy as np\n",
    "# from numpy.lib.stride_tricks import as_strided\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def max_dd(ser):\n",
    "#     #df['a'].cummax()\n",
    "#     max2here = ser.cummax()#pd.expanding_max(ser)\n",
    "#     dd2here = ser - max2here\n",
    "#     return dd2here.min()\n",
    "\n",
    "\n",
    "# s = scoreddf['CumReturns']\n",
    "# window_length = 15\n",
    "\n",
    "# #df['low'].rolling(2).apply(add_percentage_diff)\n",
    "# rolling_dd = s.rolling(window_length, min_periods=0).apply(max_dd)\n",
    "# #pd.rolling_apply(s, window_length, max_dd, min_periods=0)\n",
    "# df = pd.concat([s, rolling_dd], axis=1)\n",
    "# df.columns = ['s', 'rol_dd_%d' % window_length]\n",
    "# # =============================================================================\n",
    "# #         df.plot(linewidth=3, alpha=0.4)\n",
    "# #         #my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)\n",
    "# #         #plt.plot(my_rmdd, 'g.')\n",
    "# #         plt.show()\n",
    "# # =============================================================================\n",
    "\n",
    "# finalscores['rollingdrawdown'] = rolling_dd\n",
    "\n",
    "# #returns = -((1+df['Returns']).cumprod() -1).iloc[-1]\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# def max_dd(ser):\n",
    "#     #max2here = ser.cummax()\n",
    "#     max2here = ser.expanding().max()\n",
    "#     #max2here = pd.expanding_max(ser)\n",
    "#     dd2here = ser - max2here\n",
    "#     return dd2here.min()\n",
    "    \n",
    "\n",
    "# #Let's set up a brief series to play with to try it out:\n",
    "\n",
    "\n",
    "# np.random.seed(0)\n",
    "# n = 100\n",
    "# #s = pd.Series(np.random.randn(n).cumsum())\n",
    "# s=scoreddf['Close']\n",
    "# #rolling_dd = s.rolling(s, 10, max_dd, min_periods=0)\n",
    "# def calc_rolling_drawdown(s, window):\n",
    "#     rolling_dd = s.rolling(window, min_periods=0).apply(max_dd)\n",
    "#     df = pd.concat([s, rolling_dd], axis=1)\n",
    "#     df.columns = ['s', 'rol_dd_10']\n",
    "#     #df.plot()\n",
    "\n",
    "#     df['SP'] = econ['Close']\n",
    "\n",
    "#     df['Drawdown%'] = (df['rol_dd_10'] / df['SP'].rolling(window).max())*100\n",
    "#     econ['Drawdown% ' + str(window)] = df['Drawdown%']\n",
    "#     return econ\n",
    "\n",
    "# calc_rolling_drawdown(s, 2)\n",
    "# calc_rolling_drawdown(s, 7)\n",
    "# calc_rolling_drawdown(s, 66)\n",
    "# calc_rolling_drawdown(s, 132)\n",
    "# calc_rolling_drawdown(s, 252)\n",
    "\n",
    "# econ['Forward Return'] = econ['SP Trailing 4 Weeks Return'].shift(-22)\n",
    "# econ.loc[econ['Forward Return'] >= 0, 'positive_ret'] = 1\n",
    "# econ.loc[econ['Forward Return'] < 0, 'positive_ret'] = 0\n",
    "# number_lags = 10\n",
    "# for lag in range(1, number_lags + 1):\n",
    "#     econ['Forward lag_' + str(lag)] = econ['Forward Return'].shift(lag)\n",
    "\n",
    "# econ[['Forward lag_1', 'Forward lag_2', 'Forward lag_3', 'Forward lag_4',\n",
    "# 'Forward lag_5', 'Forward lag_6', 'Forward lag_7', 'Forward lag_8',\n",
    "# 'Forward lag_9', 'Forward lag_10']] = econ[['Forward lag_1', 'Forward lag_2', 'Forward lag_3', 'Forward lag_4',\n",
    "# 'Forward lag_5', 'Forward lag_6', 'Forward lag_7', 'Forward lag_8',\n",
    "# 'Forward lag_9', 'Forward lag_10']].copy().fillna(0)\n",
    "econ = econ.drop_duplicates()\n",
    "    \n",
    "    # subset=['CPIUS', 'MoM',\n",
    "    #     'YoY', 'm2', 'm2_growth', 'MoMGrowthChange', 'unemp_rate',\n",
    "    #     'unemp_growth', 'consumer_conf_yoy', 'MoMConsumerConf',\n",
    "    #     'RollingConsConf', 'inflation_exp_yoy', 'MoMInflationExp', 'composite_confidence_growth_yoy',\n",
    "    #     'MoMConfidence', 'mom2diff', 'ShillerOver', 'CPIDeviation', 'CPIGoalDev', 'CPIDev', 'CPIOver', 'Trade Balance'])\n",
    "#econ.tail(22)\n",
    "econ.Date = pd.to_datetime(econ['Date'])\n",
    "\n",
    "econ.set_index('Date', inplace=True)\n",
    "econW = econ#.resample('W-FRI').last()\n",
    "# data = econW[['Forward Return' , 'Close', 'SP Trailing 4 Weeks Return', 'MoMGrowthChange', 'unemp_rate', 'T10Y2Y', 'mom2diff', 'maxtight', 'ShillerOver', 'CPIDev', 'CPIOver', 'detrendedyield' , 'Drawdown% 252', 'Drawdown% 132', 'Drawdown% 66', 'Drawdown% 7', 'RollingConsConf', 'RollingExpInfl']].dropna(how='all', axis=0).fillna(0).copy()\n",
    "# dataX = data.copy().drop(['Forward Return'],axis=1)\n",
    "# dataX.head()\n",
    "# testDataX = dataX\n",
    "# testDataX.head()\n",
    "# testDataY = data['Forward Return'].copy()\n",
    "# testDataY.head()\n",
    "# from sklearn import preprocessing as pp\n",
    "\n",
    "# featuresToScale = dataX.columns\n",
    "\n",
    "# sX = pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# dataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])\n",
    "# featuresToScale = testDataX.columns\n",
    "# testDataX.loc[:,featuresToScale] = sX.fit_transform(testDataX[featuresToScale])\n",
    "# testDataX.head()\n",
    "\n",
    "# def anomalyScores(originalDF, reducedDF):\n",
    "#     loss = np.sum((np.array(originalDF) - \\\n",
    "#                     np.array(reducedDF))**2, axis=1)\n",
    "#     loss = pd.Series(data=loss,index=originalDF.index)\n",
    "#     loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "    \n",
    "#     print('Mean for anomaly scores: ', np.mean(loss))\n",
    "    \n",
    "#     return loss\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "# from tensorflow.keras.layers import BatchNormalization, Input, Lambda\n",
    "# from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "# # Call neural network API\n",
    "# model = Sequential()\n",
    "\n",
    "# # Apply linear activation function to input layer\n",
    "# # Generate hidden layer with 14 nodes, the same as the input layer\n",
    "# model.add(Dense(units=len(dataX.columns), activation='linear',input_dim=len(dataX.columns)))\n",
    "# model.add(Dense(units=14, activation='linear'))\n",
    "# model.add(Dense(units=len(dataX.columns), activation='linear'))\n",
    "# #model.add(Dropout=0.1)\n",
    "\n",
    "# # Apply linear activation function to hidden layer\n",
    "# # Generate output layer with 14 nodes\n",
    "# model.add(Dense(units=len(dataX.columns), activation='linear'))\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#                 loss='mean_squared_error',\n",
    "#                 metrics=['accuracy'])\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# batch_size = 256\n",
    "\n",
    "# history = model.fit(x=dataX, y=dataX,\n",
    "#                     epochs=num_epochs,\n",
    "#                     batch_size=batch_size,\n",
    "#                     shuffle=True,\n",
    "#                     validation_data=(dataX, dataX),\n",
    "#                     verbose=1)\n",
    "# # Evaluate on test set\n",
    "# predictions = model.predict(dataX, verbose=1)\n",
    "# anomalyScoresAE = anomalyScores(dataX, predictions)\n",
    "\n",
    "\n",
    "# anomaly = anomalyScoresAE.reset_index()\n",
    "\n",
    "# anomaly.columns=['Date', 'Reconstruction Error']\n",
    "# econW = econW.dropna(how='all', axis=0)\n",
    "# econW['Anomaly'] = anomaly.set_index('Date')\n",
    "# econW\n",
    "\n",
    "econW.rename(columns={'inflation_exp_yoy':'InflationExp', 'consumer_conf_yoy':'ConsumerConfidence'}, inplace=True)\n",
    "#print(econW.columns)\n",
    "#econW.InflationExp\n",
    "\n",
    "#econW['Combined Score']\n",
    "#econW['Combined Score'] = finalscores['Combined Economy Score']\n",
    "#finalscores.Date = pd.to_datetime(finalscores.Date)\n",
    "#econW = econW.reset_index().merge(finalscores[['Date', 'Combined Economy Score']], on='Date')\n",
    "econW.sort_values('Date', ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "#econW.to_csv(r'C:\\Users\\jonas\\OneDrive\\Skrivebord\\App\\econW.csv')\n",
    "#econW.to_csv(r'C:\\Users\\jonas\\Dropbox\\econW.csv')\n",
    "\n",
    "#print(max(econW.index))\n",
    "\n",
    "oldecon.set_index('Date', inplace=True)\n",
    "#econW = pd.concat([oldecon, econW], axis=0)\n",
    "\n",
    "#econW.to_csv(r'econWnew.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e919c281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Close</th>\n",
       "      <th>SP Daily Return</th>\n",
       "      <th>SP Trailing 4 Weeks Return</th>\n",
       "      <th>SP Trailing 1 Week Return</th>\n",
       "      <th>Cumulative Returns</th>\n",
       "      <th>CPIUS</th>\n",
       "      <th>MoM</th>\n",
       "      <th>YoY</th>\n",
       "      <th>...</th>\n",
       "      <th>RollingExpInfl</th>\n",
       "      <th>adjusted_value</th>\n",
       "      <th>composite_confidence_growth_yoy</th>\n",
       "      <th>MoMConfidence</th>\n",
       "      <th>RollingComp</th>\n",
       "      <th>Trade Balance</th>\n",
       "      <th>Trade Balance MoM</th>\n",
       "      <th>Trade Balance YoY</th>\n",
       "      <th>RollingMean12_y</th>\n",
       "      <th>real_yield</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-19</th>\n",
       "      <td>251</td>\n",
       "      <td>18322.0</td>\n",
       "      <td>1305.599976</td>\n",
       "      <td>-0.012958</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>-0.015489</td>\n",
       "      <td>72.929784</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>102.592620</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.432887</td>\n",
       "      <td>102.831528</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.148586</td>\n",
       "      <td>-8.564590</td>\n",
       "      <td>8.564590</td>\n",
       "      <td>1.737773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-20</th>\n",
       "      <td>252</td>\n",
       "      <td>18323.0</td>\n",
       "      <td>1264.739990</td>\n",
       "      <td>-0.031296</td>\n",
       "      <td>-0.045419</td>\n",
       "      <td>-0.046931</td>\n",
       "      <td>70.616082</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>102.592620</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.432887</td>\n",
       "      <td>102.831528</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.148586</td>\n",
       "      <td>-8.564590</td>\n",
       "      <td>8.564590</td>\n",
       "      <td>1.628773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-21</th>\n",
       "      <td>253</td>\n",
       "      <td>18324.0</td>\n",
       "      <td>1274.859985</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>-0.058006</td>\n",
       "      <td>-0.083655</td>\n",
       "      <td>71.189128</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>102.592620</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.432887</td>\n",
       "      <td>102.831528</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.148586</td>\n",
       "      <td>-8.564590</td>\n",
       "      <td>8.564590</td>\n",
       "      <td>1.576773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-22</th>\n",
       "      <td>254</td>\n",
       "      <td>18325.0</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.024387</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>72.949601</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>102.592620</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.432887</td>\n",
       "      <td>102.831528</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.148586</td>\n",
       "      <td>-8.564590</td>\n",
       "      <td>8.564590</td>\n",
       "      <td>1.555773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-25</th>\n",
       "      <td>255</td>\n",
       "      <td>18325.0</td>\n",
       "      <td>1305.949951</td>\n",
       "      <td>0.024387</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.070246</td>\n",
       "      <td>72.949601</td>\n",
       "      <td>174.100</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>102.592620</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.432887</td>\n",
       "      <td>102.831528</td>\n",
       "      <td>-29172.0</td>\n",
       "      <td>0.148586</td>\n",
       "      <td>-8.564590</td>\n",
       "      <td>8.564590</td>\n",
       "      <td>1.555773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-25</th>\n",
       "      <td>6517</td>\n",
       "      <td>24362.0</td>\n",
       "      <td>6040.040039</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>-0.012754</td>\n",
       "      <td>341.018125</td>\n",
       "      <td>315.493</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>-73836.0</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>-0.104139</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>1.841620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>6518</td>\n",
       "      <td>24363.0</td>\n",
       "      <td>6037.589844</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>-0.001826</td>\n",
       "      <td>340.879383</td>\n",
       "      <td>315.493</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>-73836.0</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>-0.104139</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>1.829620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>6519</td>\n",
       "      <td>24364.0</td>\n",
       "      <td>5970.839844</td>\n",
       "      <td>-0.011056</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>337.099654</td>\n",
       "      <td>315.493</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>-73836.0</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>-0.104139</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>1.869620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>6520</td>\n",
       "      <td>24365.0</td>\n",
       "      <td>5906.939941</td>\n",
       "      <td>-0.010702</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>333.481313</td>\n",
       "      <td>315.493</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>-73836.0</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>-0.104139</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>1.795620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>6521</td>\n",
       "      <td>24366.0</td>\n",
       "      <td>5881.629883</td>\n",
       "      <td>-0.004285</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>332.048128</td>\n",
       "      <td>315.493</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>-73836.0</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>-0.104139</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>1.823620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6271 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            level_0    index        Close  SP Daily Return  \\\n",
       "Date                                                         \n",
       "2000-12-19      251  18322.0  1305.599976        -0.012958   \n",
       "2000-12-20      252  18323.0  1264.739990        -0.031296   \n",
       "2000-12-21      253  18324.0  1274.859985         0.008002   \n",
       "2000-12-22      254  18325.0  1305.949951         0.024387   \n",
       "2000-12-25      255  18325.0  1305.949951         0.024387   \n",
       "...             ...      ...          ...              ...   \n",
       "2024-12-25     6517  24362.0  6040.040039         0.011043   \n",
       "2024-12-26     6518  24363.0  6037.589844        -0.000406   \n",
       "2024-12-27     6519  24364.0  5970.839844        -0.011056   \n",
       "2024-12-30     6520  24365.0  5906.939941        -0.010702   \n",
       "2024-12-31     6521  24366.0  5881.629883        -0.004285   \n",
       "\n",
       "            SP Trailing 4 Weeks Return  SP Trailing 1 Week Return  \\\n",
       "Date                                                                \n",
       "2000-12-19                   -0.036129                  -0.015489   \n",
       "2000-12-20                   -0.045419                  -0.046931   \n",
       "2000-12-21                   -0.058006                  -0.083655   \n",
       "2000-12-22                   -0.053802                  -0.070246   \n",
       "2000-12-25                   -0.053802                  -0.070246   \n",
       "...                                ...                        ...   \n",
       "2024-12-25                    0.004263                  -0.012754   \n",
       "2024-12-26                    0.011844                  -0.001826   \n",
       "2024-12-27                    0.008388                  -0.006008   \n",
       "2024-12-30                   -0.008435                  -0.013184   \n",
       "2024-12-31                   -0.015303                   0.005923   \n",
       "\n",
       "            Cumulative Returns    CPIUS       MoM       YoY  ...  \\\n",
       "Date                                                         ...   \n",
       "2000-12-19           72.929784  174.100  0.000575  0.034462  ...   \n",
       "2000-12-20           70.616082  174.100  0.000575  0.034462  ...   \n",
       "2000-12-21           71.189128  174.100  0.000575  0.034462  ...   \n",
       "2000-12-22           72.949601  174.100  0.000575  0.034462  ...   \n",
       "2000-12-25           72.949601  174.100  0.000575  0.034462  ...   \n",
       "...                        ...      ...       ...       ...  ...   \n",
       "2024-12-25          341.018125  315.493 -0.000542  0.027494  ...   \n",
       "2024-12-26          340.879383  315.493 -0.000542  0.027494  ...   \n",
       "2024-12-27          337.099654  315.493 -0.000542  0.027494  ...   \n",
       "2024-12-30          333.481313  315.493 -0.000542  0.027494  ...   \n",
       "2024-12-31          332.048128  315.493 -0.000542  0.027494  ...   \n",
       "\n",
       "            RollingExpInfl  adjusted_value  composite_confidence_growth_yoy  \\\n",
       "Date                                                                          \n",
       "2000-12-19        0.132225      102.592620                         0.001174   \n",
       "2000-12-20        0.132225      102.592620                         0.001174   \n",
       "2000-12-21        0.132225      102.592620                         0.001174   \n",
       "2000-12-22        0.132225      102.592620                         0.001174   \n",
       "2000-12-25        0.132225      102.592620                         0.001174   \n",
       "...                    ...             ...                              ...   \n",
       "2024-12-25       -0.197424       97.129856                         0.005872   \n",
       "2024-12-26       -0.197424       97.129856                         0.005872   \n",
       "2024-12-27       -0.197424       97.129856                         0.005872   \n",
       "2024-12-30       -0.197424       97.129856                         0.005872   \n",
       "2024-12-31       -0.197424       97.129856                         0.005872   \n",
       "\n",
       "            MoMConfidence  RollingComp  Trade Balance  Trade Balance MoM  \\\n",
       "Date                                                                       \n",
       "2000-12-19      -0.432887   102.831528       -29172.0           0.148586   \n",
       "2000-12-20      -0.432887   102.831528       -29172.0           0.148586   \n",
       "2000-12-21      -0.432887   102.831528       -29172.0           0.148586   \n",
       "2000-12-22      -0.432887   102.831528       -29172.0           0.148586   \n",
       "2000-12-25      -0.432887   102.831528       -29172.0           0.148586   \n",
       "...                   ...          ...            ...                ...   \n",
       "2024-12-25      -0.218452    97.391819       -73836.0          -0.043073   \n",
       "2024-12-26      -0.218452    97.391819       -73836.0          -0.043073   \n",
       "2024-12-27      -0.218452    97.391819       -73836.0          -0.043073   \n",
       "2024-12-30      -0.218452    97.391819       -73836.0          -0.043073   \n",
       "2024-12-31      -0.218452    97.391819       -73836.0          -0.043073   \n",
       "\n",
       "            Trade Balance YoY  RollingMean12_y  real_yield  \n",
       "Date                                                        \n",
       "2000-12-19          -8.564590         8.564590    1.737773  \n",
       "2000-12-20          -8.564590         8.564590    1.628773  \n",
       "2000-12-21          -8.564590         8.564590    1.576773  \n",
       "2000-12-22          -8.564590         8.564590    1.555773  \n",
       "2000-12-25          -8.564590         8.564590    1.555773  \n",
       "...                       ...              ...         ...  \n",
       "2024-12-25          -0.104139        -0.028274    1.841620  \n",
       "2024-12-26          -0.104139        -0.028274    1.829620  \n",
       "2024-12-27          -0.104139        -0.028274    1.869620  \n",
       "2024-12-30          -0.104139        -0.028274    1.795620  \n",
       "2024-12-31          -0.104139        -0.028274    1.823620  \n",
       "\n",
       "[6271 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldecon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f2f53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Close</th>\n",
       "      <th>SP Daily Return</th>\n",
       "      <th>SP Trailing 4 Weeks Return</th>\n",
       "      <th>SP Trailing 1 Week Return</th>\n",
       "      <th>Cumulative Returns</th>\n",
       "      <th>CPIUS</th>\n",
       "      <th>MoM</th>\n",
       "      <th>YoY</th>\n",
       "      <th>...</th>\n",
       "      <th>RollingExpInfl</th>\n",
       "      <th>adjusted_value</th>\n",
       "      <th>composite_confidence_growth_yoy</th>\n",
       "      <th>MoMConfidence</th>\n",
       "      <th>RollingComp</th>\n",
       "      <th>Trade Balance</th>\n",
       "      <th>Trade Balance MoM</th>\n",
       "      <th>Trade Balance YoY</th>\n",
       "      <th>RollingMean12_y</th>\n",
       "      <th>real_yield</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [level_0, index, Close, SP Daily Return, SP Trailing 4 Weeks Return, SP Trailing 1 Week Return, Cumulative Returns, CPIUS, MoM, YoY, RollingMean12_x, m2, m2_growth, MoMGrowthChange, meanvalue_x, OneYearYield, TenYield, spread, unemp_rate, unemp_growth, meanvalue_y, T10Y2Y, Inverted12months, Shiller_P/E, ConsumerConfidence, MoMConsumerConf, RollingConsConf, InflationExp, MoMInflationExp, RollingExpInfl, adjusted_value, composite_confidence_growth_yoy, MoMConfidence, RollingComp, Trade Balance, Trade Balance MoM, Trade Balance YoY, RollingMean12_y, real_yield]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d543dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
