{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://www.dropbox.com/oauth2/authorize?response_type=code&client_id=55yk24u9ydtvsdr\n",
      "Click 'Allow' and copy the authorization code.\n"
     ]
    }
   ],
   "source": [
    "import dropbox\n",
    "from dropbox import DropboxOAuth2FlowNoRedirect\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# Create a dummy expiration time (e.g., 4 hours from now)\n",
    "expiration = datetime.now() + timedelta(hours=4)\n",
    "\n",
    "APP_KEY = \"55yk24u9ydtvsdr\"\n",
    "APP_SECRET = \"cy6f9fenucdpof3\"\n",
    "\n",
    "access_token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "auth_flow = DropboxOAuth2FlowNoRedirect(APP_KEY, APP_SECRET)\n",
    "authorize_url = auth_flow.start()\n",
    "print(f\"Go to: {authorize_url}\")\n",
    "print(\"Click 'Allow' and copy the authorization code.\")\n",
    "auth_code = input(\"Enter the authorization code: \").strip()\n",
    "\n",
    "try:\n",
    "    oauth_result = auth_flow.finish(auth_code)\n",
    "    access_token = oauth_result.access_token\n",
    "    refresh_token = oauth_result.refresh_token\n",
    "    expiration = oauth_result.expires_at\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "dbx = dropbox.Dropbox(oauth2_access_token=access_token)\n",
    "def refresh_access_token(refresh_token):\n",
    "    try:\n",
    "        dbx = dropbox.Dropbox(\n",
    "            oauth2_refresh_token=refresh_token,\n",
    "            app_key=APP_KEY,\n",
    "            app_secret=APP_SECRET\n",
    "        )\n",
    "        return dbx.oauth2_refresh_access_token()\n",
    "    except Exception as e:\n",
    "        print(f\"Error refreshing token: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_and_refresh_token():\n",
    "    global access_token, expiration\n",
    "    if pd.to_datetime(datetime.now()) >= expiration:\n",
    "        new_token = refresh_access_token(refresh_token)\n",
    "        if new_token:\n",
    "            access_token = new_token.access_token\n",
    "            expiration = new_token.expires_at\n",
    "            dbx._oauth2_access_token = access_token\n",
    "        else:\n",
    "            print(\"Failed to refresh token\")\n",
    "\n",
    "\n",
    "# Before making API calls, check and refresh the token if necessary\n",
    "check_and_refresh_token()\n",
    "# Now you can use the dbx object to make API calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to: https://www.dropbox.com/oauth2/authorize?response_type=code&client_id=55yk24u9ydtvsdr\n",
      "Click 'Allow' and copy the authorization code.\n"
     ]
    }
   ],
   "source": [
    "import dropbox\n",
    "from dropbox import DropboxOAuth2FlowNoRedirect\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "APP_KEY = \"55yk24u9ydtvsdr\"\n",
    "APP_SECRET = \"cy6f9fenucdpof3\"\n",
    "REFRESH_TOKEN_FILE = r\"C:\\Users\\jonas\\Downloads\\finpage-1\\src\\refresh_token.txt\"\n",
    "\n",
    "def get_refresh_token():\n",
    "    if os.path.exists(REFRESH_TOKEN_FILE):\n",
    "        with open(REFRESH_TOKEN_FILE, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "def save_refresh_token(refresh_token):\n",
    "    with open(REFRESH_TOKEN_FILE, \"w\") as f:\n",
    "        f.write(refresh_token)\n",
    "\n",
    "def initial_auth():\n",
    "    auth_flow = DropboxOAuth2FlowNoRedirect(APP_KEY, APP_SECRET)\n",
    "    authorize_url = auth_flow.start()\n",
    "    print(f\"Go to: {authorize_url}\")\n",
    "    print(\"Click 'Allow' and copy the authorization code.\")\n",
    "    auth_code = input(\"Enter the authorization code: \").strip()\n",
    "\n",
    "    try:\n",
    "        oauth_result = auth_flow.finish(auth_code)\n",
    "        save_refresh_token(oauth_result.refresh_token)\n",
    "        return oauth_result.access_token, oauth_result.refresh_token, oauth_result.expires_at\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def refresh_access_token(refresh_token, APP_KEY, APP_SECRET):\n",
    "    try:\n",
    "        dbx = dropbox.Dropbox(\n",
    "            oauth2_refresh_token=refresh_token,\n",
    "            app_key=APP_KEY,\n",
    "            app_secret=APP_SECRET\n",
    "        )\n",
    "        return dbx.oauth2_refresh_access_token()\n",
    "    except Exception as e:\n",
    "        print(f\"Error refreshing token: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_dropbox_object():\n",
    "    refresh_token = get_refresh_token()\n",
    "    if not refresh_token:\n",
    "        access_token, refresh_token, expiration = initial_auth()\n",
    "    else:\n",
    "        token_result = refresh_access_token(refresh_token)\n",
    "        if token_result:\n",
    "            access_token = token_result.access_token\n",
    "            expiration = token_result.expires_at\n",
    "        else:\n",
    "            print(\"Failed to refresh token. Re-authenticating...\")\n",
    "            access_token, refresh_token, expiration = initial_auth()\n",
    "\n",
    "    return dropbox.Dropbox(oauth2_access_token=access_token)\n",
    "\n",
    "# Main script\n",
    "dbx = get_dropbox_object()\n",
    "# Now you can use the dbx object to make API calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_token = get_refresh_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_KEY = \"55yk24u9ydtvsdr\"\n",
    "APP_SECRET = \"cy6f9fenucdpof3\"\n",
    "REFRESH_TOKEN_FILE = \"refresh_token.txt\"\n",
    "dbx = dropbox.Dropbox(\n",
    "    oauth2_refresh_token=refresh_token,\n",
    "    app_key=APP_KEY,\n",
    "    app_secret=APP_SECRET\n",
    ")\n",
    "new_access_token = dbx.check_and_refresh_access_token()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refresh_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 401: Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://drive.google.com/file/d/1J47a0_lyfhRzcYlniXUKE-5yVKNbWX6j/view?usp=sharing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\urllib\\request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 401: Unauthorized"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('https://drive.google.com/file/d/1J47a0_lyfhRzcYlniXUKE-5yVKNbWX6j/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Close</th>\n",
       "      <th>SP Daily Return</th>\n",
       "      <th>SP Trailing 4 Weeks Return</th>\n",
       "      <th>SP Trailing 1 Week Return</th>\n",
       "      <th>Cumulative Returns</th>\n",
       "      <th>CPIUS</th>\n",
       "      <th>...</th>\n",
       "      <th>Forward lag_2</th>\n",
       "      <th>Forward lag_3</th>\n",
       "      <th>Forward lag_4</th>\n",
       "      <th>Forward lag_5</th>\n",
       "      <th>Forward lag_6</th>\n",
       "      <th>Forward lag_7</th>\n",
       "      <th>Forward lag_8</th>\n",
       "      <th>Forward lag_9</th>\n",
       "      <th>Forward lag_10</th>\n",
       "      <th>Combined Economy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1983-04-22</td>\n",
       "      <td>863.0</td>\n",
       "      <td>13858.0</td>\n",
       "      <td>160.419998</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.062326</td>\n",
       "      <td>0.027147</td>\n",
       "      <td>8.083805</td>\n",
       "      <td>293.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.028732</td>\n",
       "      <td>0.024853</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.047713</td>\n",
       "      <td>0.058657</td>\n",
       "      <td>0.069679</td>\n",
       "      <td>0.084789</td>\n",
       "      <td>18.757588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1983-04-29</td>\n",
       "      <td>867.0</td>\n",
       "      <td>13862.0</td>\n",
       "      <td>162.949997</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>0.063154</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>8.227067</td>\n",
       "      <td>293.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.042378</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.028732</td>\n",
       "      <td>0.024853</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>18.870345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1983-05-06</td>\n",
       "      <td>873.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>166.100006</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.087659</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>8.405436</td>\n",
       "      <td>293.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>-0.012406</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.025025</td>\n",
       "      <td>0.025025</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.042378</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>17.770060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1983-05-13</td>\n",
       "      <td>878.0</td>\n",
       "      <td>13873.0</td>\n",
       "      <td>164.910004</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.047713</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>8.338052</td>\n",
       "      <td>293.400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024827</td>\n",
       "      <td>-0.026838</td>\n",
       "      <td>-0.020048</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>-0.012406</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>17.982215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1983-05-20</td>\n",
       "      <td>883.0</td>\n",
       "      <td>13878.0</td>\n",
       "      <td>162.139999</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>8.181200</td>\n",
       "      <td>293.400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.022766</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>-0.013822</td>\n",
       "      <td>-0.024827</td>\n",
       "      <td>-0.026838</td>\n",
       "      <td>-0.020048</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>18.163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>2178</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>11753.0</td>\n",
       "      <td>24377.0</td>\n",
       "      <td>5996.660156</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>-0.018798</td>\n",
       "      <td>-0.006366</td>\n",
       "      <td>338.561733</td>\n",
       "      <td>315.605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>0.019794</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>41.451297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>2179</td>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>11758.0</td>\n",
       "      <td>24381.0</td>\n",
       "      <td>6101.240234</td>\n",
       "      <td>-0.002855</td>\n",
       "      <td>0.042888</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>344.483595</td>\n",
       "      <td>315.605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027684</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>41.352069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>2180</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>11763.0</td>\n",
       "      <td>24386.0</td>\n",
       "      <td>6040.529785</td>\n",
       "      <td>-0.005047</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>341.045857</td>\n",
       "      <td>315.605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027684</td>\n",
       "      <td>41.499092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>2181</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>11768.0</td>\n",
       "      <td>24391.0</td>\n",
       "      <td>6025.990234</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>340.222553</td>\n",
       "      <td>315.605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.764411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>2182</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>11773.0</td>\n",
       "      <td>24396.0</td>\n",
       "      <td>6114.629883</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>345.241786</td>\n",
       "      <td>317.671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.769785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2183 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Date  level_0    index        Close  SP Daily Return  \\\n",
       "0              0  1983-04-22    863.0  13858.0   160.419998         0.002312   \n",
       "1              1  1983-04-29    867.0  13862.0   162.949997         0.009353   \n",
       "2              2  1983-05-06    873.0  13868.0   166.100006         0.011079   \n",
       "3              3  1983-05-13    878.0  13873.0   164.910004         0.004018   \n",
       "4              4  1983-05-20    883.0  13878.0   162.139999         0.000926   \n",
       "...          ...         ...      ...      ...          ...              ...   \n",
       "2178        2178  2025-01-17  11753.0  24377.0  5996.660156         0.009991   \n",
       "2179        2179  2025-01-24  11758.0  24381.0  6101.240234        -0.002855   \n",
       "2180        2180  2025-01-31  11763.0  24386.0  6040.529785        -0.005047   \n",
       "2181        2181  2025-02-07  11768.0  24391.0  6025.990234        -0.009465   \n",
       "2182        2182  2025-02-14  11773.0  24396.0  6114.629883        -0.000072   \n",
       "\n",
       "      SP Trailing 4 Weeks Return  SP Trailing 1 Week Return  \\\n",
       "0                       0.062326                   0.027147   \n",
       "1                       0.063154                   0.010642   \n",
       "2                       0.087659                   0.015265   \n",
       "3                       0.047713                   0.011765   \n",
       "4                       0.007965                  -0.023863   \n",
       "...                          ...                        ...   \n",
       "2178                   -0.018798                  -0.006366   \n",
       "2179                    0.042888                   0.048403   \n",
       "2180                    0.016803                   0.003625   \n",
       "2181                    0.018106                   0.002615   \n",
       "2182                    0.046579                   0.012784   \n",
       "\n",
       "      Cumulative Returns    CPIUS  ...  Forward lag_2  Forward lag_3  \\\n",
       "0               8.083805  293.400  ...       0.007965       0.028732   \n",
       "1               8.227067  293.400  ...       0.027192       0.042378   \n",
       "2               8.405436  293.400  ...       0.010102       0.002714   \n",
       "3               8.338052  293.400  ...      -0.024827      -0.026838   \n",
       "4               8.181200  293.400  ...       0.033168       0.022766   \n",
       "...                  ...      ...  ...            ...            ...   \n",
       "2178          338.561733  315.605  ...       0.046579       0.036967   \n",
       "2179          344.483595  315.605  ...       0.000000       0.000000   \n",
       "2180          341.045857  315.605  ...       0.000000       0.000000   \n",
       "2181          340.222553  315.605  ...       0.000000       0.000000   \n",
       "2182          345.241786  317.671  ...       0.000000       0.000000   \n",
       "\n",
       "      Forward lag_4  Forward lag_5  Forward lag_6  Forward lag_7  \\\n",
       "0          0.024853       0.029291       0.042942       0.047713   \n",
       "1          0.018763       0.013058       0.007965       0.028732   \n",
       "2         -0.012406       0.009267       0.025025       0.025025   \n",
       "3         -0.020048       0.003348       0.006797       0.010102   \n",
       "4          0.003760       0.003592      -0.013822      -0.024827   \n",
       "...             ...            ...            ...            ...   \n",
       "2178       0.041438       0.025039       0.019794       0.018106   \n",
       "2179       0.000000       0.027684       0.046579       0.046579   \n",
       "2180       0.000000       0.000000       0.000000       0.000000   \n",
       "2181       0.000000       0.000000       0.000000       0.000000   \n",
       "2182       0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "      Forward lag_8  Forward lag_9  Forward lag_10  Combined Economy Score  \n",
       "0          0.058657       0.069679        0.084789               18.757588  \n",
       "1          0.024853       0.029291        0.042942               18.870345  \n",
       "2          0.027192       0.042378        0.018763               17.770060  \n",
       "3          0.002714      -0.012406        0.009267               17.982215  \n",
       "4         -0.026838      -0.020048        0.003348               18.163558  \n",
       "...             ...            ...             ...                     ...  \n",
       "2178       0.020027       0.028854        0.019202               41.451297  \n",
       "2179       0.036967       0.041438        0.025039               41.352069  \n",
       "2180       0.000000       0.000000        0.027684               41.499092  \n",
       "2181       0.000000       0.000000        0.000000               41.764411  \n",
       "2182       0.000000       0.000000        0.000000               38.769785  \n",
       "\n",
       "[2183 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_id = '1J47a0_lyfhRzcYlniXUKE-5yVKNbWX6j'\n",
    "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
    "df = pd.read_csv(download_url)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "YFRateLimitError",
     "evalue": "Too Many Requests. Rate limited. Try after a while.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mYFRateLimitError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfredapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fred\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m SP \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^GSPC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhistory(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\base.py:81\u001b[0m, in \u001b[0;36mTickerBase.history\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mlog_indent_decorator\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhistory\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_price_history()\u001b[38;5;241m.\u001b[39mhistory(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\scrapers\\history.py:175\u001b[0m, in \u001b[0;36mPriceHistory.history\u001b[1;34m(self, period, interval, start, end, prepost, actions, auto_adjust, back_adjust, repair, keepna, proxy, rounding, timeout, raise_errors)\u001b[0m\n\u001b[0;32m    173\u001b[0m         get_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcache_get\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     data \u001b[38;5;241m=\u001b[39m get_fn(\n\u001b[0;32m    176\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    177\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    178\u001b[0m         proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    179\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill be right back\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur engineers are working quickly to resolve \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe issue. Thank you for your patience.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\data.py:335\u001b[0m, in \u001b[0;36mYfData.get\u001b[1;34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mlog_indent_decorator\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, user_agent_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(url, request_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mget, user_agent_headers\u001b[38;5;241m=\u001b[39muser_agent_headers, params\u001b[38;5;241m=\u001b[39mparams, proxy\u001b[38;5;241m=\u001b[39mproxy, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\yfinance\\data.py:397\u001b[0m, in \u001b[0;36mYfData._make_request\u001b[1;34m(self, url, request_method, user_agent_headers, body, params, proxy, timeout)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# Raise exception if rate limited\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m YFRateLimitError()\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[1;31mYFRateLimitError\u001b[0m: Too Many Requests. Rate limited. Try after a while."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.models import load_model\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "#%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "\n",
    "SP = yf.Ticker(\"^GSPC\").history(period='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^GSPC']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [(Adj Close, ^GSPC), (Close, ^GSPC), (High, ^GSPC), (Low, ^GSPC), (Open, ^GSPC), (Volume, ^GSPC)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "# Set the ticker symbol for S&P 500\n",
    "ticker = \"^GSPC\"  # Use \"SPY\" for SPDR S&P 500 ETF\n",
    "\n",
    "# Set date range\n",
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "end_date = datetime.datetime.now()\n",
    "\n",
    "# Download the data\n",
    "sp500_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Display the first few rows\n",
    "print(sp500_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.models import load_model\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "#%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "\n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max')\n",
    "\n",
    "\n",
    "start = datetime.datetime(1980, 1, 1)\n",
    "#end = datetime(2022, 5, 27)\n",
    "end = datetime.datetime.now()\n",
    "spread = web.DataReader('T10Y2Y', 'fred', start, end)\n",
    "spread.reset_index(inplace=True)\n",
    "#plt.plot(spread.DATE, spread.T10Y2Y.add(0))\n",
    "spread.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "spread['Date']=pd.to_datetime(spread['Date'])\n",
    "\n",
    "#spread = spread.resample('D', on=\"Date\").min()\n",
    "#.apply(lambda x : x.iloc[0])\n",
    "\n",
    "#spread.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#spread.set_index('Date', inplace=True)\n",
    "#spread.reset_index(inplace=True)\n",
    "#spread = spread.drop('NotDate', axis=1)\n",
    "#spread.tail(50)\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() < 0, 'Inverted12months'] = 1\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() > 0, 'Inverted12months'] = 0\n",
    "    \n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "SP = pd.DataFrame(fred.get_series('SP500')).reset_index()\n",
    "SP.columns = ['Date','Close']\n",
    "\n",
    "Stock = SP\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>2097.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>2110.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>2109.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>2115.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>2113.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>6051.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>6115.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>6114.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6129.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Close\n",
       "0    2015-02-19  2097.45\n",
       "1    2015-02-20  2110.30\n",
       "2    2015-02-23  2109.66\n",
       "3    2015-02-24  2115.48\n",
       "4    2015-02-25  2113.86\n",
       "...         ...      ...\n",
       "2604 2025-02-12  6051.97\n",
       "2605 2025-02-13  6115.07\n",
       "2606 2025-02-14  6114.63\n",
       "2607 2025-02-17      NaN\n",
       "2608 2025-02-18  6129.58\n",
       "\n",
       "[2609 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenyearmin = pd.DataFrame(fred.get_series('DGS1')).reset_index()\n",
    "tenyearmin.columns = ['Date','Close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>2025-02-10</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16466</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16467</th>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16468</th>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16469 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Close\n",
       "0     1962-01-02   3.22\n",
       "1     1962-01-03   3.24\n",
       "2     1962-01-04   3.24\n",
       "3     1962-01-05   3.26\n",
       "4     1962-01-08   3.31\n",
       "...          ...    ...\n",
       "16464 2025-02-10   4.24\n",
       "16465 2025-02-11   4.25\n",
       "16466 2025-02-12   4.30\n",
       "16467 2025-02-13   4.27\n",
       "16468 2025-02-14   4.23\n",
       "\n",
       "[16469 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenyearmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_18788\\602365302.py:86: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  Stock['SP Daily Return'] = Stock['Close'].pct_change()\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_18788\\602365302.py:133: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['MoM'] = cpius['value'].pct_change()\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_18788\\602365302.py:134: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_18788\\602365302.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "c:\\Users\\jonas\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time imports: 45.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Local\\Temp\\ipykernel_18788\\602365302.py:473: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  econ = completedates.merge(Stock, on='Date', how='left').merge(cpius, on='Date', how='left').merge(m2, on='Date', how='left').merge(yieldmin, on='Date', how='left').merge(unemp, on='Date', how='left').merge(spread, on='Date', how='left').merge(shiller, on='Date', how='left').merge(consumer_confidence, on='Date', how='left').merge(inflation_exp, on='Date', how='left').merge(composite_confidence, on='Date', how='left').ffill()\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.models import load_model\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "import dropbox\n",
    "import io\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_datareader import wb\n",
    "import matplotlib.dates as mdates\n",
    "import sys \n",
    "sys.version\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "token = 'sl.u.AFjjQNO3MVo7z6zjW1yPvaECsPeQxJSSK-pSyNB_lzRRvhdAf_Yta04g4UhsGWFZ5yidFS81E_c472AdQU_KM4daRjA-eWqHjfBsG32cqClBFVYShrFURRkxooHaMTeA46TkX3147_SeIdYcfJHbfnPVwlk9MY4phWGjJc8zTLt3a0qNlyz-h_kAWYhQUJw2ik3QegCmhAUNW5qn9cTi8ba9HwF-R0aDv_GEcPoajRSvp9C-N59zrCiFuAKbPrvOXKItJGJ_YTY006Lpxo__oNE2kzTMOyIh9qnzDcIioxT0bJnGo7tA4-3to-tmeeILZyh1xMT-75mCDnNN54Ys9B6Bawmfyi5wp2DGvQlGZ5jgD5mux3fGdwezx75spblhHFf-ha5ZGKmzZWlIbGWx7zYwfxN9CDemMEZ1Y5-dQuWiyjTasM5cAr1C_uH9meriN7poaBMJr1wxQIs4Nuw1KTs4nq5Xp7mV2EY0yy6Rkk-ugiyYzcnswBTahsngnvDyJ0D6s_4fmfJRW8Zji3wotpYFzmuWrf2-fG-C8xXGqWXae9qBatS9FmyQNpuOAVP5Jjhp_6GvZz8np6lb-mMbnL_S1ieTKmb_aPFl01vlwfGw44OxY6ys741_MVCf2sl6q3q2HDuIb2P5NEAkDhpBNcMmoOJtRXqBudrhF7Oj9jEb1dZ47ZooFe2Rk21mk00j6MyHW7Ro4wblwSib3P-ZULQn6MwIPP4CTmyZxTfVHosgY9F2t9hmHlW9umQuw7LeC8riA_fw5Hk-PSqUhDio0KMRc-IujybUVXkcwaLXvAqYpBIq1H8T-YlJXNcnLF1rRne9kk8EZaStyY28Vsns8p5sNzHZAQ4mfD9U-hhIS05nlli7p2Go2uJx_QXIRUxCyeCzCHHMlsEHBh548N3evwVkXNDYImMx61lG-h8vjNqKK7VPKSkdSjV2FHzS4VWoGixIMGLgrY-d4PrQTGeiA5lwOsL4i7S4aokNxx8VN-9Ym8FHmkvu3fPvX2FQmLPBe9Pt1-mi66D3Q6j34YKz45NO3cg36gfyFlmKfkkkn8868HaBYyhh7tYVQJ2-iK7wAM7HoBugTLVPo1FPie6tXnn0m8W-B6PhrBps2ebSJHBHru7-HFrd2INlN0Rn7K1bqHvvthlTQoxGV2LbJb3Fk2ks9VnlJzUv7ZYAioRgQPvNfXvUU2xbJXwRfbmGVUXeeYtmCQToEUB7wi4A4OWAWjMhi6rO_w83gk6hGmIeymQ06nLl8SL-RJVSP78yLp5v_jWAvTX2KUJKyBYRXFSTeJ88EvRLw10UR-pF00Vpzo6fLA'\n",
    "\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "#%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "\n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max')\n",
    "\n",
    "\n",
    "start = datetime.datetime(1980, 1, 1)\n",
    "#end = datetime(2022, 5, 27)\n",
    "end = datetime.datetime.now()\n",
    "spread = web.DataReader('T10Y2Y', 'fred', start, end)\n",
    "spread.reset_index(inplace=True)\n",
    "#plt.plot(spread.DATE, spread.T10Y2Y.add(0))\n",
    "spread.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "spread['Date']=pd.to_datetime(spread['Date'])\n",
    "\n",
    "#spread = spread.resample('D', on=\"Date\").min()\n",
    "#.apply(lambda x : x.iloc[0])\n",
    "\n",
    "#spread.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#spread.set_index('Date', inplace=True)\n",
    "#spread.reset_index(inplace=True)\n",
    "#spread = spread.drop('NotDate', axis=1)\n",
    "#spread.tail(50)\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() < 0, 'Inverted12months'] = 1\n",
    "spread.loc[spread['T10Y2Y'].rolling(window=153, min_periods=1).min() > 0, 'Inverted12months'] = 0\n",
    "    \n",
    "#SP = yf.Ticker(\"^GSPC\").history(period='max').reset_index()\n",
    "SP = pd.DataFrame(fred.get_series('SP500', observation_start=start, observation_end=end)).reset_index()\n",
    "SP.columns = ['Date','Close']\n",
    "\n",
    "Stock = SP\n",
    "Stock['Date'] = pd.to_datetime(Stock['Date'])\n",
    "\n",
    "#Stock = Stock.resample('W-MON', on=\"Date\").apply(lambda x : x.iloc[0])\n",
    "#Stock\n",
    "#Stock.rename(columns={'Date':'NotDate'}, inplace=True)\n",
    "#Stock.set_index('Date', inplace=True)\n",
    "#Stock.reset_index(inplace=True)\n",
    "#Stock = Stock.drop('NotDate', axis=1)\n",
    "\n",
    "Stock['SP Daily Return'] = Stock['Close'].pct_change()\n",
    "Stock['SP Trailing 4 Weeks Return'] = Stock['SP Daily Return'].shift(1).rolling(21, min_periods=21).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "Stock['SP Trailing 1 Week Return'] = Stock['SP Daily Return'].shift(1).rolling(7, min_periods=7).apply(lambda x: np.prod(1 + x) - 1).fillna(0)\n",
    "\n",
    "#Stock['SP Daily Return'].apply(lambda x: np.prod(1 + x) - 1)\n",
    "#.rolling\n",
    "#.prod()#.cumprod()\n",
    "#Stock\n",
    "Stock.isnull().sum()\n",
    "\n",
    "Stock['Cumulative Returns'] = (1 + Stock['SP Daily Return']).cumprod() - 1\n",
    "Stock.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "#df = pd.read_excel('sample.xlsx')\n",
    "\n",
    "#print(df)\n",
    "\n",
    "release_dates = pd.read_excel('https://alfred.stlouisfed.org/release/downloaddates?rid=10&ff=xls',skiprows= range(1,36))['Release: Consumer Price Index'].copy()\n",
    "\n",
    "release_dates = pd.to_datetime(release_dates)\n",
    "\n",
    "release_dates = pd.DataFrame(release_dates)\n",
    "release_dates.rename(columns={'Release: Consumer Price Index':'Release Date'}, inplace=True)\n",
    "\n",
    "#import datetime\n",
    "#import dateutil.relativedelta\n",
    "\n",
    "#years_ago = datetime.datetime.now() - relativedelta(years=7)\n",
    "release_dates['Date'] = release_dates['Release Date'] - pd.DateOffset(months=1)\n",
    "\n",
    "#\n",
    "\n",
    "#d = (\"2013-03-31\", \"%Y-%m-%d\")\n",
    "release_dates['Date'] = release_dates['Date'].to_numpy().astype('datetime64[M]')\n",
    "release_dates['Date'] = pd.to_datetime(release_dates['Date'])\n",
    "FRED_API_KEY = '29f9bb6865c0b3be320b44a846d539ea'\n",
    "fred = Fred(FRED_API_KEY)\n",
    "\n",
    "cpius = fred.get_series_all_releases('CPIAUCNS', realtime_start=start.date())\n",
    "\n",
    "cpius = cpius.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "cpius = cpius.sort_index()\n",
    "\n",
    "cpius.reset_index(inplace= True)\n",
    "cpius = cpius.drop_duplicates(subset='Date', keep='last')\n",
    "# cpius = cpius.drop_duplicates('Date', keep='last')\n",
    "cpius['MoM'] = cpius['value'].pct_change()\n",
    "cpius['YoY'] = cpius['value'].pct_change(periods=12)\n",
    "cpius['RollingMean12'] = cpius['value'].pct_change(periods=12).rolling(12, min_periods=1).mean()\n",
    "\n",
    "#cpius.reset_index(inplace= True)\n",
    "cpius['Date'] = pd.to_datetime(cpius['Date']) \n",
    "\n",
    "# cpius = cpius.merge(release_dates, on=\"Date\")\n",
    "\n",
    "# cpius = cpius.drop('Date', axis=1).rename(columns={'Release Date' : 'Date'}).set_index('Date')\n",
    "# cpius.reset_index(inplace= True)\n",
    "cpius.rename({'value':'CPIUS'}, axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "#%matplotlib inline\n",
    "#from requests_html import AsyncHTMLSession\n",
    "figsize(20, 5)\n",
    "pd.options.display.max_colwidth = 60\n",
    "\n",
    "m2 = fred.get_series_all_releases('M2SL', realtime_start=start.date())\n",
    "m2['date'] = pd.to_datetime(m2['date'])\n",
    "m2['value'] = m2['value'].astype(float)\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(m2.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "m2 = m2.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "m2.tail(10)\n",
    "m2 = m2.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "m2.reset_index(inplace= True)\n",
    "m2 = m2.drop_duplicates('Date', keep='last')\n",
    "m2['Date'] = pd.to_datetime(m2['Date'])\n",
    "m2.rename(columns={'value':'m2'}, inplace=True)\n",
    "    \n",
    "#     # lei = fred.get_series_all_releases('USALOLITONOSTSAM')\n",
    "#     # lei['date'] = pd.to_datetime(lei['date'])\n",
    "#     # lei['value'] = lei['value'].astype(float)\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # meanvalues = pd.DataFrame(lei.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "    \n",
    "#     # lei = lei.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#     # lei['lei_growth'] = lei['value'].pct_change(periods=12)\n",
    "#     # lei['MoMGrowthChange'] = lei['lei_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "#     # lei.tail(10)\n",
    "#     # lei = lei.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "    \n",
    "#     # lei.reset_index(inplace= True)\n",
    "#     # lei =lei.drop_duplicates('Date', keep='last')\n",
    "#     # lei['Date'] = pd.to_datetime(lei['Date'])\n",
    "#     # lei.rename(columns={'value':'lei'}, inplace=True)\n",
    "    \n",
    "unemp = fred.get_series_all_releases('UNRATE', realtime_start=start.date())\n",
    "unemp['date'] = pd.to_datetime(unemp['date'])\n",
    "unemp['value'] = unemp['value'].astype(float)\n",
    "\n",
    "unemp['unemp_growth'] = unemp['value'].pct_change()\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "meanvalues = pd.DataFrame(unemp.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "unemp = unemp.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "#m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "#m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "unemp.tail(10)\n",
    "unemp = unemp.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "unemp.reset_index(inplace= True)\n",
    "unemp = unemp.drop_duplicates('Date', keep='last')\n",
    "unemp['Date'] = pd.to_datetime(unemp['Date'])\n",
    "unemp.rename(columns={'value':'unemp_rate'}, inplace=True)\n",
    "    \n",
    "    \n",
    "# tenyearmin = yf.Ticker(\"^TNX\").history(period='max')\n",
    "\n",
    "# #tenyearmin = web.DataReader('DGS10', 'fred', start=start, end=end)\n",
    "# tenyearmin = pd.DataFrame(tenyearmin['Close']).copy()\n",
    "\n",
    "# tenyearmin.reset_index(inplace=True)\n",
    "\n",
    "tenyearmin = pd.DataFrame(fred.get_series('DGS10', observation_start=start)).reset_index()\n",
    "tenyearmin.columns = ['Date','Close']\n",
    "\n",
    "\n",
    "tenyearmin['Date'] = pd.to_datetime(tenyearmin['Date'])\n",
    "\n",
    "\n",
    "oneyearmin = pd.DataFrame(fred.get_series('DGS1', observation_start=start)).reset_index()\n",
    "oneyearmin.columns = ['Date','Close']\n",
    "# oneyearmin = yf.Ticker(\"^IRX\").history(period='max')\n",
    "# #oneyearmin = web.DataReader('DGS1', 'fred', start=start, end=end)\n",
    "# oneyearmin = pd.DataFrame(oneyearmin['Close']).copy()\n",
    "\n",
    "# oneyearmin.reset_index(inplace=True)\n",
    "\n",
    "oneyearmin['Date'] = pd.to_datetime(oneyearmin['Date'])\n",
    "\n",
    "yieldmin = oneyearmin.merge(tenyearmin, on=\"Date\")\n",
    "yieldmin['spread'] = yieldmin['Close_y'] - yieldmin['Close_x']\n",
    "\n",
    "yieldmin.rename(columns={'Close_x':'OneYearYield', 'Close_y':'TenYield'}, inplace=True)\n",
    "yieldmin.fillna(0, inplace=True)\n",
    "yieldmin.rename(columns={'DATE':'Date'}, inplace=True)\n",
    "\n",
    "completedates = pd.DataFrame(pd.date_range(start=start, end=datetime.datetime.now(), freq='B'), columns=['Date'])\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "from requests import get\n",
    "import itertools\n",
    "import re\n",
    "from scipy import signal\n",
    "my_url = \"https://www.multpl.com/shiller-pe/table/by-month\"\n",
    "session = HTMLSession()\n",
    "response = session.get(my_url)\n",
    "page_content = response.text\n",
    "soup = bs(page_content, 'html.parser')\n",
    "\n",
    "\n",
    "#soup.find_all(\"h2\", string = re.compile(\"header\"))\n",
    "table = soup.select(\"table\")[0]\n",
    "\n",
    "#actual_values = [link['left'] for link in table]\n",
    "\n",
    "columns = soup.find('th', class_=\"left\")\n",
    "#columns\n",
    "\n",
    "table_rows = table.find_all(\"tr\")\n",
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [str(tr.get_text()).strip() for tr in td]\n",
    "    l.append(row) \n",
    "#print(table_rows)\n",
    "l=list(itertools.chain(*l))\n",
    "Dates = l[0::2]\n",
    "Values = l[1::2]\n",
    "shillers = pd.DataFrame(columns = [Dates, Values]).T.reset_index()\n",
    "shillers.columns = ['Date', 'Value']\n",
    "shillers['Date'] = pd.to_datetime(shillers['Date'])\n",
    "shillers['Value'] = shillers['Value'].astype(float)\n",
    "\n",
    "shiller = shillers\n",
    "\n",
    "\n",
    "#shiller = pd.read_csv(r'C:\\Users\\jonas\\OneDrive\\Skrivebord\\shillers.csv')\n",
    "shiller['Date'] = pd.to_datetime(shiller['Date'])\n",
    "shiller.columns = ['Date', 'Shiller_P/E'] \n",
    "\n",
    "# consumer_credit = fred.get_series_all_releases('TOTLL') #Total Consumer Credit\n",
    "# consumer_credit['date'] = pd.to_datetime(consumer_credit['date'])\n",
    "# #lei.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "\n",
    "# consumer_credit['value'] = consumer_credit['value'].astype(float)\n",
    "# consumer_credit['consumer_credit_growth_yoy'] = consumer_credit['value'].pct_change(periods=12)\n",
    "# consumer_credit['MoMGrowthChange'] = consumer_credit['consumer_credit_growth_yoy'].pct_change()\n",
    "# consumer_credit\n",
    "# meanvalues = pd.DataFrame(consumer_credit.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "# consumer_credit = consumer_credit.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "# consumer_credit['consumer_credit_growth'] = consumer_credit['value'].pct_change(periods=12)\n",
    "# consumer_credit['MoMGrowthChange'] = consumer_credit['consumer_credit_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# consumer_credit.tail(10)\n",
    "# consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# consumer_credit.reset_index(inplace= True)\n",
    "# consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# consumer_credit['Date'] = pd.to_datetime(consumer_credit['Date'])\n",
    "# consumer_credit.rename(columns={'value':'consumer_credit_growth'}, inplace=True)\n",
    "# consumer_credit\n",
    "composite_confidence = fred.get_series_all_releases('CSCICP03USM665S', realtime_start=start.date()) \n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "composite_confidence.head(20)\n",
    "composite_confidence['adjusted_value'] = composite_confidence['value'].shift(2).astype(float)\n",
    "composite_confidence['composite_confidence_growth_yoy'] = composite_confidence['adjusted_value'].pct_change(periods=12)\n",
    "composite_confidence['MoMConfidence'] = composite_confidence['composite_confidence_growth_yoy'].pct_change()\n",
    "composite_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "composite_confidence['date'] = pd.to_datetime(composite_confidence['date'])\n",
    "composite_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "composite_confidence = composite_confidence.drop(['realtime_start', 'value'], axis=1).set_index('Date').reset_index()\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "composite_confidence['RollingComp'] = composite_confidence.adjusted_value.rolling(12).mean()\n",
    "composite_confidence\n",
    "\n",
    "inflation_exp = fred.get_series_all_releases('MICH', realtime_start=start.date()) #Total Consumer Credit\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "inflation_exp.head(20)\n",
    "inflation_exp['adjusted_value'] = inflation_exp['value'].shift(2).astype(float)\n",
    "inflation_exp['inflation_exp_yoy'] = inflation_exp['adjusted_value'].pct_change(periods=12)\n",
    "inflation_exp['MoMInflationExp'] = inflation_exp['inflation_exp_yoy'].pct_change()\n",
    "inflation_exp\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "inflation_exp['date'] = pd.to_datetime(inflation_exp['date'])\n",
    "inflation_exp.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "inflation_exp = inflation_exp.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "inflation_exp['RollingExpInfl'] = inflation_exp.inflation_exp_yoy.rolling(12).mean()\n",
    "inflation_exp\n",
    "\n",
    "consumer_confidence = fred.get_series_all_releases('UMCSENT', realtime_start=start.date()) #Total Consumer Credit\n",
    "consumer_confidence.dropna(inplace=True)\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "consumer_confidence.head(20)\n",
    "consumer_confidence['adjusted_value'] = consumer_confidence['value'].shift(2).astype(float)\n",
    "consumer_confidence['consumer_conf_yoy'] = consumer_confidence['adjusted_value'].pct_change(periods=12)\n",
    "consumer_confidence['MoMConsumerConf'] = consumer_confidence['consumer_conf_yoy'].pct_change()\n",
    "consumer_confidence\n",
    "\n",
    "#consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "#consumer_credit.reset_index(inplace= True)\n",
    "#consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "consumer_confidence['date'] = pd.to_datetime(consumer_confidence['date'])\n",
    "consumer_confidence.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "consumer_confidence = consumer_confidence.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "consumer_confidence['RollingConsConf'] = consumer_confidence.consumer_conf_yoy.rolling(12).mean()\n",
    "consumer_confidence\n",
    "\n",
    "import_end = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = import_end - start_time\n",
    "print(f\"Elapsed time imports: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# df = fred.search('ism')\n",
    "# #TOTALNS# ( Consumer Credit)\n",
    "# #TOTLL # Loans and leases\n",
    "# #CCLACBW027SBOGc\n",
    "# #PAYEMS (NON FARM PAYROLL)\n",
    "# # UMCSENT ( Consumer Confidence)\n",
    "# # MICH (Inflation Expectations)\n",
    "# # CSCICP03USM665S ( Composite Confidence Indicatiors) , two previous best\n",
    "\n",
    "# df.iloc[0,3]\n",
    "# df\n",
    "\n",
    "# housing = fred.get_series_all_releases('HSN1F') #Total Consumer Credit\n",
    "# housing.dropna(inplace=True)\n",
    "# housing['date'] = pd.to_datetime(housing['date'])\n",
    "\n",
    "# housing.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "# housing['adjusted_value'] = housing['value'].shift(2).astype(float)\n",
    "# housing['housing_yoy'] = housing['adjusted_value'].pct_change(periods=12)\n",
    "# housing['MoMRetail'] = housing['housing_yoy'].pct_change()\n",
    "# housing\n",
    "\n",
    "# #consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# #consumer_credit.reset_index(inplace= True)\n",
    "# #consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# housing['date'] = pd.to_datetime(housing['date'])\n",
    "# housing.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "# housing = housing.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "# housing['RollingHousing'] = housing.housing_yoy.rolling(12).mean()\n",
    "\n",
    "\n",
    "# claims = fred.get_series_all_releases('CFSBCACTIVITYNMFG') #Total Consumer Credit\n",
    "# claims.dropna(inplace=True)\n",
    "\n",
    "# claims = fred.get_series_all_releases('CFSBCACTIVITYNMFG') #Total Consumer Credit\n",
    "# claims.dropna(inplace=True)\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "\n",
    "# claims.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "# claims['adjusted_value'] = claims['value'].shift(2).astype(float)\n",
    "# claims['housing_yoy'] = claims['adjusted_value'].pct_change(periods=12)\n",
    "# claims['MoMRetail'] = claims['housing_yoy'].pct_change()\n",
    "# claims\n",
    "\n",
    "# #consumer_credit = consumer_credit.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# #consumer_credit.reset_index(inplace= True)\n",
    "# #consumer_credit =consumer_credit.drop_duplicates('Date', keep='last')\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "# claims.rename(columns={'date':'Date'}, inplace=True)\n",
    "\n",
    "# claims = claims.drop(['realtime_start', 'value', 'adjusted_value'], axis=1).set_index('Date').reset_index()\n",
    "# claims['RollingHousing'] = claims.housing_yoy.rolling(12).mean()\n",
    "# claims\n",
    "# claims = fred.get_series_all_releases('ICSA')\n",
    "# claims.dropna(inplace=True)\n",
    "# claims['date'] = pd.to_datetime(claims['date'])\n",
    "# claims['value'] = claims['value'].astype(float)\n",
    "\n",
    "# claims['claims_growth'] = claims['value'].pct_change()\n",
    "# claims['claims_yoy'] = claims['value'].pct_change(periods=12)\n",
    "# #m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# meanvalues = pd.DataFrame(claims.groupby(['date'])['value'].mean()).rename(columns={'value':'meanvalue'}).drop_duplicates(subset='meanvalue', keep='first')\n",
    "\n",
    "# claims = claims.merge(meanvalues, on='date', how='left').drop_duplicates(subset = ['date'],keep='first').copy()\n",
    "# #m2['m2_growth'] = m2['value'].pct_change(periods=12)\n",
    "# #m2['MoMGrowthChange'] = m2['m2_growth'].pct_change() # Theory: Effect on stock market is shown next month\n",
    "# claims.tail(10)\n",
    "# claims = claims.drop('date', axis=1).rename(columns={'realtime_start' : 'Date'}).set_index('Date')\n",
    "\n",
    "# claims.reset_index(inplace= True)\n",
    "# claims = claims.drop_duplicates('Date', keep='last')\n",
    "# claims['Date'] = pd.to_datetime(claims['Date'])\n",
    "# claims.rename(columns={'value':'claims'}, inplace=True)\n",
    "# claims\n",
    "\n",
    "import pytz\n",
    "\n",
    "time_zone = 'America/New_York'\n",
    "dfs = [completedates, Stock, cpius, m2, yieldmin, unemp, spread, shiller, consumer_confidence, inflation_exp, composite_confidence]\n",
    "for df in dfs:\n",
    "    #df = df.reset_index()\n",
    "    for col in df.columns:\n",
    "        if col == \"Date\":\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "            # extract just the date component\n",
    "            df[col] = df[col].dt.date\n",
    "            #df[col] = df[col].Date\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "econ = completedates.merge(Stock, on='Date', how='left').merge(cpius, on='Date', how='left').merge(m2, on='Date', how='left').merge(yieldmin, on='Date', how='left').merge(unemp, on='Date', how='left').merge(spread, on='Date', how='left').merge(shiller, on='Date', how='left').merge(consumer_confidence, on='Date', how='left').merge(inflation_exp, on='Date', how='left').merge(composite_confidence, on='Date', how='left').ffill()\n",
    "#.apply(lambda x : x.iloc[0]).head(32)\n",
    "econ.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "econ['real_yield'] = econ['TenYield'] - (econ['YoY']*100)\n",
    "#plt.plot(econ.Date, econ.real_yield)\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "econ = econ.dropna(axis=0).copy()\n",
    "detrended = signal.detrend(econ.m2)\n",
    "\n",
    "detrended_df = pd.DataFrame(detrended)\n",
    "\n",
    "\n",
    "econ['detrendedm2'] = detrended\n",
    "#econ['M2Detrend'] = econ.detrendedm2.diff(252)\n",
    "#econ['CPIDeviation'] = abs(econ['CPIDetrend'] - econ['CPIDetrend'].mean())\n",
    "\n",
    "#plt.plot(econ['Date'], econ['m2'].apply(np.log).diff(252).rolling(120).mean())\n",
    "econ['mom2diff'] = econ['m2'].apply(np.log).diff(252).diff(252).rolling(1).mean()\n",
    "\n",
    "#def calc_MDD(Stock):\n",
    "df = pd.Series(econ['TenYield'], name=\"nw\").to_frame()\n",
    "\n",
    "min_peaks_idx = df.nw.expanding(min_periods=1).apply(lambda x: x.argmin()).fillna(0).astype(int)\n",
    "df['max_peaks_idx'] = pd.Series(min_peaks_idx).to_frame()\n",
    "\n",
    "min_peaks = pd.Series(df.nw.iloc[min_peaks_idx.values].values, index=df.nw.index)\n",
    "\n",
    "df['dd'] = ((df.nw-min_peaks)/min_peaks)\n",
    "df['maxtightening'] = df.groupby('max_peaks_idx').dd.apply(lambda x: x.expanding(min_periods=1).apply(lambda y: y.max())).fillna(0).reset_index(drop=True)\n",
    "\n",
    "#  return df\n",
    "\n",
    "econ['maxtight'] = df['maxtightening']\n",
    "\n",
    "econ['TenYieldNorm'] = econ.TenYield.rolling(window=104).mean().copy()\n",
    "econ['TenYieldNorm'] =(((econ['TenYieldNorm']  -\n",
    "econ['TenYieldNorm'] .min()) /\n",
    "(econ['TenYieldNorm'] .max() -\n",
    "econ['TenYieldNorm'] .min())) * 100).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>SP Daily Return</th>\n",
       "      <th>SP Trailing 4 Weeks Return</th>\n",
       "      <th>SP Trailing 1 Week Return</th>\n",
       "      <th>Cumulative Returns</th>\n",
       "      <th>CPIUS</th>\n",
       "      <th>MoM</th>\n",
       "      <th>YoY</th>\n",
       "      <th>...</th>\n",
       "      <th>RollingExpInfl</th>\n",
       "      <th>adjusted_value</th>\n",
       "      <th>composite_confidence_growth_yoy</th>\n",
       "      <th>MoMConfidence</th>\n",
       "      <th>RollingComp</th>\n",
       "      <th>real_yield</th>\n",
       "      <th>detrendedm2</th>\n",
       "      <th>mom2diff</th>\n",
       "      <th>maxtight</th>\n",
       "      <th>TenYieldNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>9168</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>2110.30</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>234.812</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>100.314734</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>99.625478</td>\n",
       "      <td>1.373507</td>\n",
       "      <td>794.069805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>9169</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>2109.66</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>234.812</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>100.314734</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>99.625478</td>\n",
       "      <td>1.303507</td>\n",
       "      <td>789.439646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>9170</td>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>2115.48</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>234.812</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>100.314734</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>99.625478</td>\n",
       "      <td>1.233507</td>\n",
       "      <td>784.809488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>9171</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>2113.86</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>234.812</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>100.314734</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>99.625478</td>\n",
       "      <td>1.203507</td>\n",
       "      <td>780.179329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>9172</td>\n",
       "      <td>2015-02-26</td>\n",
       "      <td>2110.74</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>233.707</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>100.314734</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>99.625478</td>\n",
       "      <td>2.119348</td>\n",
       "      <td>775.549171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11772</th>\n",
       "      <td>11772</td>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>6115.07</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>1.915478</td>\n",
       "      <td>317.671</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>1.519517</td>\n",
       "      <td>-1429.362854</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.089925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11773</th>\n",
       "      <td>11773</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>6114.63</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>1.915269</td>\n",
       "      <td>317.671</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>1.469517</td>\n",
       "      <td>-1433.993013</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.280917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11774</th>\n",
       "      <td>11774</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>6114.63</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029860</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>1.915269</td>\n",
       "      <td>317.671</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>1.469517</td>\n",
       "      <td>-1438.623171</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.474561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11775</th>\n",
       "      <td>11775</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6129.58</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>1.922396</td>\n",
       "      <td>317.671</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>1.469517</td>\n",
       "      <td>-1443.253329</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.654942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11776</th>\n",
       "      <td>11776</td>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>6129.58</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>1.922396</td>\n",
       "      <td>317.671</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197424</td>\n",
       "      <td>97.129856</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.218452</td>\n",
       "      <td>97.391819</td>\n",
       "      <td>1.469517</td>\n",
       "      <td>-1447.883488</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.835323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        Date    Close  SP Daily Return  \\\n",
       "9168    9168  2015-02-20  2110.30         0.006126   \n",
       "9169    9169  2015-02-23  2109.66        -0.000303   \n",
       "9170    9170  2015-02-24  2115.48         0.002759   \n",
       "9171    9171  2015-02-25  2113.86        -0.000766   \n",
       "9172    9172  2015-02-26  2110.74        -0.001476   \n",
       "...      ...         ...      ...              ...   \n",
       "11772  11772  2025-02-13  6115.07         0.010426   \n",
       "11773  11773  2025-02-14  6114.63        -0.000072   \n",
       "11774  11774  2025-02-17  6114.63         0.000000   \n",
       "11775  11775  2025-02-18  6129.58         0.002445   \n",
       "11776  11776  2025-02-19  6129.58         0.002445   \n",
       "\n",
       "       SP Trailing 4 Weeks Return  SP Trailing 1 Week Return  \\\n",
       "9168                     0.000000                   0.000000   \n",
       "9169                     0.000000                   0.000000   \n",
       "9170                     0.000000                   0.000000   \n",
       "9171                     0.000000                   0.000000   \n",
       "9172                     0.000000                   0.000000   \n",
       "...                           ...                        ...   \n",
       "11772                    0.035780                   0.009575   \n",
       "11773                    0.027758                   0.012784   \n",
       "11774                    0.029860                   0.008768   \n",
       "11775                    0.019673                   0.005106   \n",
       "11776                    0.019673                   0.005106   \n",
       "\n",
       "       Cumulative Returns    CPIUS       MoM       YoY  ...  RollingExpInfl  \\\n",
       "9168             0.006126  234.812 -0.005670  0.007565  ...       -0.004237   \n",
       "9169             0.005821  234.812 -0.005670  0.007565  ...       -0.004237   \n",
       "9170             0.008596  234.812 -0.005670  0.007565  ...       -0.004237   \n",
       "9171             0.007824  234.812 -0.005670  0.007565  ...       -0.004237   \n",
       "9172             0.006336  233.707 -0.004706 -0.000893  ...       -0.004237   \n",
       "...                   ...      ...       ...       ...  ...             ...   \n",
       "11772            1.915478  317.671  0.006546  0.030005  ...       -0.197424   \n",
       "11773            1.915269  317.671  0.006546  0.030005  ...       -0.197424   \n",
       "11774            1.915269  317.671  0.006546  0.030005  ...       -0.197424   \n",
       "11775            1.922396  317.671  0.006546  0.030005  ...       -0.197424   \n",
       "11776            1.922396  317.671  0.006546  0.030005  ...       -0.197424   \n",
       "\n",
       "       adjusted_value  composite_confidence_growth_yoy  MoMConfidence  \\\n",
       "9168       100.314734                         0.018191       0.351857   \n",
       "9169       100.314734                         0.018191       0.351857   \n",
       "9170       100.314734                         0.018191       0.351857   \n",
       "9171       100.314734                         0.018191       0.351857   \n",
       "9172       100.314734                         0.018191       0.351857   \n",
       "...               ...                              ...            ...   \n",
       "11772       97.129856                         0.005872      -0.218452   \n",
       "11773       97.129856                         0.005872      -0.218452   \n",
       "11774       97.129856                         0.005872      -0.218452   \n",
       "11775       97.129856                         0.005872      -0.218452   \n",
       "11776       97.129856                         0.005872      -0.218452   \n",
       "\n",
       "       RollingComp  real_yield  detrendedm2  mom2diff  maxtight  TenYieldNorm  \n",
       "9168     99.625478    1.373507   794.069805       NaN       NaN           NaN  \n",
       "9169     99.625478    1.303507   789.439646       NaN       NaN           NaN  \n",
       "9170     99.625478    1.233507   784.809488       NaN       NaN           NaN  \n",
       "9171     99.625478    1.203507   780.179329       NaN       NaN           NaN  \n",
       "9172     99.625478    2.119348   775.549171       NaN       NaN           NaN  \n",
       "...            ...         ...          ...       ...       ...           ...  \n",
       "11772    97.391819    1.519517 -1429.362854   0.05863       NaN     95.089925  \n",
       "11773    97.391819    1.469517 -1433.993013   0.05863       NaN     95.280917  \n",
       "11774    97.391819    1.469517 -1438.623171   0.05863       NaN     95.474561  \n",
       "11775    97.391819    1.469517 -1443.253329   0.05863       NaN     95.654942  \n",
       "11776    97.391819    1.469517 -1447.883488   0.05863       NaN     95.835323  \n",
       "\n",
       "[2609 rows x 39 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'AAPL' reason: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/AAPL?range=1d&interval=1d&crumb=Edge%3A+Too+Many+Requests (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000231FCD65340>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "$AAPL: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'MSFT' reason: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/MSFT?range=1d&interval=1d&crumb=Edge%3A+Too+Many+Requests (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000231FF60E630>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "$MSFT: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'GOOGL' reason: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/GOOGL?range=1d&interval=1d&crumb=Edge%3A+Too+Many+Requests (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000231FF3E4350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "$GOOGL: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import time\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000)\n",
    "def fetch_data(ticker):\n",
    "    data = yf.Ticker(ticker)\n",
    "    return data.history(period=\"1d\")\n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        data = fetch_data(ticker)\n",
    "        print(data)\n",
    "        time.sleep(1)  # Sleep for 1 second between requests\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash\n",
    "from dash import html, dcc\n",
    "#from update_script import update_dropbox_dataset\n",
    "from dash import dcc, callback, html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "    'background': 'rgb(240,241,245)',\n",
    "    'text': 'black',\n",
    "    'accent': '#004172',\n",
    "    'text-white':'white',\n",
    "    'content':'#EDF3F4'\n",
    "}\n",
    "\n",
    "fonts = {\n",
    "    'heading': 'Helvetica',\n",
    "    'body': 'Helvetica'\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    'background': '#f4f4f4',\n",
    "    'banner': '#0a213b',\n",
    "    'banner2': '#1e3a5a',\n",
    "    'content': '#859db3',\n",
    "    'text': '#859db3',\n",
    "    'accent': '#004172',\n",
    "    'border': '#bed6eb',\n",
    "    'header': '#7a7a7a',\n",
    "    'element': '#1f8c44',\n",
    "    'text-white': 'white',\n",
    "}\n",
    "\n",
    "\n",
    "file_id = '1J47a0_lyfhRzcYlniXUKE-5yVKNbWX6j'\n",
    "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
    "economy = pd.read_csv(download_url)\n",
    "\n",
    "#economy = pd.read_csv(\"https://www.dropbox.com/scl/fi/4xgez6scpfj5sh46eokxa/econW.csv?rlkey=nk06610ol4qtck25uum6o3n5l&st=wt5378pm&dl=1\").drop(['Unnamed: 0', 'level_0'], axis=1)\n",
    "latestdate = str(pd.to_datetime(economy['Date']).dt.date.tail(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-02-28'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latestdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
